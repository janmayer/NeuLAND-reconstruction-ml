{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicity determination with Scikit-learn classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test out scikit-learn classification models for multiplicity reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import multiprocessing\n",
    "import functools\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helpers import filename_for\n",
    "from plotconf import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ALL the classification models from scikit-learn.\n",
    "Note that some models are very slow to train with large datasets or crash outright, so we give them a reduced number of (shuffled) rows to learn.\n",
    "Note that `n_jobs=1` is used, as parallelism is introduced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_a1 = [\n",
    "    (\"BaggingClassifier\", sklearn.ensemble.BaggingClassifier(n_jobs=1), \"medi\"),\n",
    "    (\"BernoulliNB\", sklearn.naive_bayes.BernoulliNB(), \"fast\"),\n",
    "    (\"CalibratedClassifierCV\", sklearn.calibration.CalibratedClassifierCV(cv=5), \"slow\"),\n",
    "    (\"ComplementNB\", sklearn.naive_bayes.ComplementNB(), \"fast\"),\n",
    "    (\"GaussianNB\", sklearn.naive_bayes.GaussianNB(), \"fast\"),\n",
    "]\n",
    "\n",
    "models_a2 = [\n",
    "    (\"LinearDiscriminantAnalysis\", sklearn.discriminant_analysis.LinearDiscriminantAnalysis(), \"fast\"),\n",
    "    (\"LinearSVC\", sklearn.svm.LinearSVC(max_iter=20000), \"slow\"),  # slow with unscaled data\n",
    "    (\n",
    "        \"LogisticRegression\",\n",
    "        sklearn.linear_model.LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\", max_iter=20000),\n",
    "        \"slow\",\n",
    "    ),  # slow with unscaled data\n",
    "    (\n",
    "        \"LogisticRegressionCV\",\n",
    "        sklearn.linear_model.LogisticRegressionCV(cv=5, solver=\"lbfgs\", multi_class=\"auto\", max_iter=20000),\n",
    "        \"slow\",\n",
    "    ),\n",
    "    (\"MLPClassifier\", sklearn.neural_network.MLPClassifier(), \"slow\"),\n",
    "    (\"MultinomialNB\", sklearn.naive_bayes.MultinomialNB(), \"fast\"),\n",
    "]\n",
    "\n",
    "models_b = [\n",
    "    (\"NearestCentroid\", sklearn.neighbors.NearestCentroid(), \"fast\"),\n",
    "    (\n",
    "        \"PassiveAggressiveClassifier\",\n",
    "        sklearn.linear_model.PassiveAggressiveClassifier(max_iter=1000, tol=1e-3, n_jobs=1),\n",
    "        \"fast\",\n",
    "    ),\n",
    "    (\"Perceptron\", sklearn.linear_model.Perceptron(n_jobs=1), \"fast\"),\n",
    "    (\"QuadraticDiscriminantAnalysis\", sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis(), \"fast\"),\n",
    "    (\"RidgeClassifier\", sklearn.linear_model.RidgeClassifier(), \"fast\"),\n",
    "    (\"RidgeClassifierCV\", sklearn.linear_model.RidgeClassifierCV(), \"fast\"),\n",
    "    (\"SGDClassifier\", sklearn.linear_model.SGDClassifier(max_iter=5000, tol=1e-3, n_jobs=1), \"medi\"),\n",
    "]\n",
    "\n",
    "# Run these sequential due to \"buffer source array is read-only\" with LokyBackend\n",
    "models_s = [\n",
    "    (\"AdaBoostClassifier\", sklearn.ensemble.AdaBoostClassifier(), \"fast\"),\n",
    "    (\"DecisionTreeClassifier\", sklearn.tree.DecisionTreeClassifier(), \"medi\"),\n",
    "    (\"ExtraTreeClassifier\", sklearn.tree.ExtraTreeClassifier(), \"fast\"),\n",
    "    (\"ExtraTreesClassifier\", sklearn.ensemble.ExtraTreesClassifier(n_estimators=100, n_jobs=-1), \"medi\"),\n",
    "    (\"RandomForestClassifier\", sklearn.ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1), \"medi\"),\n",
    "]\n",
    "\n",
    "# Models that fail alot\n",
    "models_o = [\n",
    "    # ('NuSVC', sklearn.svm.NuSVC(), 'fast'),  # nu infeasible\n",
    "    (\"RadiusNeighborsClassifier\", sklearn.neighbors.RadiusNeighborsClassifier(radius=3, n_jobs=-1), \"medi\"),\n",
    "    (\"GaussianProcessClassifier\", sklearn.gaussian_process.GaussianProcessClassifier(), \"slow\"),\n",
    "    # ('GradientBoostingClassifier', sklearn.ensemble.GradientBoostingClassifier(), 'slow'),  # crashes\n",
    "    # ('HistGradientBoostingClassifier', sklearn.ensemble.HistGradientBoostingClassifier(), 'slow'),  # crashes?\n",
    "    (\"KNeighborsClassifier\", sklearn.neighbors.KNeighborsClassifier(n_jobs=10), \"slow\"),\n",
    "    (\n",
    "        \"LabelPropagation\",\n",
    "        sklearn.semi_supervised.LabelPropagation(),\n",
    "        \"slow\",\n",
    "    ),  # requires too much memory to train with larger datasets\n",
    "    (\"LabelSpreading\", sklearn.semi_supervised.LabelSpreading(), \"slow\"),  # bit slow\n",
    "    (\"SVC\", sklearn.svm.SVC(gamma=\"scale\"), \"slow\"),  # slow, not timeouted\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some models only work with properly scaled data, so we prepare ALL available scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnscaledScaler(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.to_numpy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X, y)\n",
    "\n",
    "\n",
    "scalers = [\n",
    "    (\"Unscaled data\", UnscaledScaler()),\n",
    "    (\"standard scaling\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"min-max scaling\", sklearn.preprocessing.MinMaxScaler()),\n",
    "    (\"max-abs scaling\", sklearn.preprocessing.MaxAbsScaler()),\n",
    "    (\"robust scaling\", sklearn.preprocessing.RobustScaler(quantile_range=(25, 75))),\n",
    "    # (\"power transformation (Yeo-Johnson)\", sklearn.preprocessing.PowerTransformer(method=\"yeo-johnson\")), # complains about shapes\n",
    "    # ('power transformation (Box-Cox)', sklearn.preprocessing.PowerTransformer(method='box-cox')), # 'strictly zero' meh.\n",
    "    (\"quantile transformation (gaussian pdf)\", sklearn.preprocessing.QuantileTransformer(output_distribution=\"normal\")),\n",
    "    (\"quantile transformation (uniform pdf)\", sklearn.preprocessing.QuantileTransformer(output_distribution=\"uniform\")),\n",
    "    (\"sample-wise L2 normalizing\", sklearn.preprocessing.Normalizer()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Train and Test data is passed through the scalers, including the \"unscaled\" scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nPN</th>\n",
       "      <th>nPP</th>\n",
       "      <th>nPH</th>\n",
       "      <th>nHits</th>\n",
       "      <th>nClus</th>\n",
       "      <th>Edep</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197061</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418403</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410944</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674027</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755310</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150672</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286466</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307234</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604782</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>1210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166335</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        nPN  nPP  nPH  nHits  nClus  Edep    0    1    2    3  ...  5990  \\\n",
       "197061    1    1    1      2      2    71  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "418403    3    3    3     39     11   818  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "410944    3    3    3     39     21   741  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "674027    4    3    3     45     24   748  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "755310    4    3    3     52     18   866  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "...     ...  ...  ...    ...    ...   ...  ...  ...  ...  ...  ...   ...   \n",
       "150672    1    1    1     15      6   309  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "286466    2    2    2     17      9   387  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "307234    2    2    2     20     11   312  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "604782    4    4    4     65     20  1210  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "166335    1    1    1     11      3   371  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "        5991  5992  5993  5994  5995  5996  5997  5998  5999  \n",
       "197061   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "418403   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "410944   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "674027   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "755310   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "150672   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "286466   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "307234   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "604782   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "166335   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[8000 rows x 6006 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = [filename_for(15, 30, 600, 500, n, \"inclxx\", s, \"bars.pkl\") for n in [1, 2, 3, 4] for s in range(20)]\n",
    "dfs = [pd.read_pickle(file) for file in files]\n",
    "data = pd.concat(dfs, ignore_index=True).sample(frac=0.01)\n",
    "data.loc[data[\"nHits\"] == 0, \"nPN\"] = 0\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6428, 6006)\n",
      "(1572, 6006)\n"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(data.shape[0]) < 0.8\n",
    "msk[0] = True\n",
    "msk[1] = False\n",
    "\n",
    "traindata = data[msk]\n",
    "testdata = data[~msk]\n",
    "\n",
    "print(traindata.shape)\n",
    "print(testdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Features: nHits, nClus, and Edep normally, but HitE / HitT from all bars together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_tri = [\"nHits\", \"nClus\", \"Edep\"]\n",
    "cols_e = [i for i in range(0, 30 * 100 * 2, 2)]\n",
    "cols_t = [i + 1 for i in range(0, 30 * 100 * 2, 2)]\n",
    "\n",
    "scalers_trained = [\n",
    "    (\n",
    "        sname,\n",
    "        copy.copy(scaler).fit(traindata[cols_tri]),\n",
    "        copy.copy(scaler).fit(traindata[cols_e].values.reshape(-1, 1)),\n",
    "        copy.copy(scaler).fit(traindata[cols_t].values.reshape(-1, 1)),\n",
    "    )\n",
    "    for sname, scaler in scalers\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = [\n",
    "    (\n",
    "        sname,\n",
    "        np.concatenate(\n",
    "            (\n",
    "                s_tri.transform(traindata[cols_tri]),\n",
    "                s_e.transform(traindata[cols_e].values.reshape(-1, 1)).reshape(-1, len(cols_e)),\n",
    "                s_t.transform(traindata[cols_t].values.reshape(-1, 1)).reshape(-1, len(cols_t)),\n",
    "            ),\n",
    "            axis=1,\n",
    "        ),\n",
    "        np.concatenate(\n",
    "            (\n",
    "                s_tri.transform(testdata[cols_tri]),\n",
    "                s_e.transform(testdata[cols_e].values.reshape(-1, 1)).reshape(-1, len(cols_e)),\n",
    "                s_t.transform(testdata[cols_t].values.reshape(-1, 1)).reshape(-1, len(cols_t)),\n",
    "            ),\n",
    "            axis=1,\n",
    "        ),\n",
    "    )\n",
    "    for sname, s_tri, s_e, s_t in scalers_trained\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all model/scaler combinations, in parallel.\n",
    "Note that we use timeouts per task, as setting at timeout in joblib will throw everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_timeout(timeout):\n",
    "    def decorator(decorated):\n",
    "        @functools.wraps(decorated)\n",
    "        def inner(*args, **kwargs):\n",
    "            pool = multiprocessing.pool.ThreadPool(1)\n",
    "            async_result = pool.apply_async(decorated, args, kwargs)\n",
    "            try:\n",
    "                return async_result.get(timeout)\n",
    "            except multiprocessing.TimeoutError:\n",
    "                return\n",
    "\n",
    "        return inner\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIHEAD = 50000\n",
    "SLOWHEAD = 5000\n",
    "label = \"nPN\"\n",
    "\n",
    "y_train_fast = traindata[[label]].values.ravel()\n",
    "y_train_medi = traindata.head(MEDIHEAD)[[label]].values.ravel()\n",
    "y_train_slow = traindata.head(SLOWHEAD)[[label]].values.ravel()\n",
    "y_test = testdata[[label]].values.ravel()\n",
    "\n",
    "\n",
    "@with_timeout(1200 * 2)\n",
    "def train_model(mname, modelorg, speed, sname, x_train, x_test):\n",
    "    # These get killed without error?\n",
    "    if mname == \"RadiusNeighborsClassifier\" and sname != \"Unscaled data\":\n",
    "        return (mname, sname, np.NaN, speed, np.NaN, \"Skipped\")\n",
    "    try:\n",
    "        model = sklearn.base.clone(modelorg)\n",
    "        start = time.time()\n",
    "        if speed == \"slow\":\n",
    "            model.fit(x_train[0:SLOWHEAD], y_train_slow)\n",
    "        elif speed == \"medi\":\n",
    "            model.fit(x_train[0:MEDIHEAD], y_train_medi)\n",
    "        elif speed == \"fast\":\n",
    "            model.fit(x_train, y_train_fast)\n",
    "        end = time.time()\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_true = y_test\n",
    "\n",
    "        bac = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "        return (mname, sname, bac, speed, (end - start), \"ok\")\n",
    "    except Exception as err:\n",
    "        return (mname, sname, np.NaN, speed, np.NaN, err)\n",
    "\n",
    "\n",
    "def train_model_wrap(mname, modelorg, speed, sname, x_train, x_test):\n",
    "    ret = train_model(mname, modelorg, speed, sname, x_train, x_test)\n",
    "    if ret:\n",
    "        return ret\n",
    "    else:\n",
    "        return (mname, sname, np.NaN, speed, np.NaN, \"Timeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    results_a1 = Parallel(n_jobs=10, verbose=1)(\n",
    "        delayed(train_model_wrap)(mname, modelorg, speed, sname, x_train, x_test)\n",
    "        for sname, x_train, x_test in data_scaled\n",
    "        for mname, modelorg, speed in models_a1\n",
    "    )\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results_a2 = Parallel(n_jobs=10, verbose=1)(\n",
    "        delayed(train_model_wrap)(mname, modelorg, speed, sname, x_train, x_test)\n",
    "        for sname, x_train, x_test in data_scaled\n",
    "        for mname, modelorg, speed in models_a2\n",
    "    )\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results_b = Parallel(n_jobs=10, verbose=1)(\n",
    "        delayed(train_model_wrap)(mname, modelorg, speed, sname, x_train, x_test)\n",
    "        for sname, x_train, x_test in data_scaled\n",
    "        for mname, modelorg, speed in models_b\n",
    "    )\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results_s = Parallel(n_jobs=1, verbose=1)(\n",
    "        delayed(train_model_wrap)(mname, modelorg, speed, sname, x_train, x_test)\n",
    "        for sname, x_train, x_test in data_scaled\n",
    "        for mname, modelorg, speed in models_s\n",
    "    )\n",
    "except Exception as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_o = []\n",
    "for mname, modelorg, speed in models_o:\n",
    "    try:\n",
    "        tmp = Parallel(n_jobs=10, verbose=1)(\n",
    "            delayed(train_model_wrap)(mname, modelorg, speed, sname, x_train, x_test)\n",
    "            for sname, x_train, x_test in data_scaled\n",
    "        )\n",
    "        results_o.extend(tmp)\n",
    "    except Exception as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results_a1 + results_a2 + results_b + results_s + results_o\n",
    "resultsdf = pd.DataFrame(results)\n",
    "pd.options.display.max_rows = 999\n",
    "resultsdf.columns = [\"Model\", \"Scaler\", \"BAC\", \"Speed\", \"Time\", \"Status\"]\n",
    "resultsdf.sort_values(by=[\"BAC\", \"Time\"], ascending=[False, True], inplace=True)\n",
    "resultsdf.style.hide_index().format({\"BAC\": \"{:.2%}\", \"Time\": \"{:.2f}\"}).bar(subset=[\"BAC\"], color=\"lightgreen\").bar(\n",
    "    subset=[\"Time\"], color=\"lightblue\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
