{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to improve Cluster classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import multiprocessing\n",
    "import functools\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "import skopt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helpers import filename_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Rebalance (Downsample), Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    8670780\n",
      "1.0    1782525\n",
      "Name: prim, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_event</th>\n",
       "      <th>prim</th>\n",
       "      <th>T</th>\n",
       "      <th>E</th>\n",
       "      <th>Size</th>\n",
       "      <th>EToF</th>\n",
       "      <th>EnergyMoment</th>\n",
       "      <th>TSpawn</th>\n",
       "      <th>MaxEHit</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3499177</th>\n",
       "      <td>1731.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.755749</td>\n",
       "      <td>149.914871</td>\n",
       "      <td>6.0</td>\n",
       "      <td>607.207764</td>\n",
       "      <td>6.798460e+00</td>\n",
       "      <td>1.218181</td>\n",
       "      <td>64.293854</td>\n",
       "      <td>-0.682722</td>\n",
       "      <td>-22.500000</td>\n",
       "      <td>1522.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8869071</th>\n",
       "      <td>3484.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.362877</td>\n",
       "      <td>15.335159</td>\n",
       "      <td>4.0</td>\n",
       "      <td>580.952515</td>\n",
       "      <td>3.743494e+00</td>\n",
       "      <td>0.394498</td>\n",
       "      <td>9.338829</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>-1.970521</td>\n",
       "      <td>1757.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585062</th>\n",
       "      <td>5713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.605553</td>\n",
       "      <td>37.585819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.481689</td>\n",
       "      <td>2.278178e-13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.585819</td>\n",
       "      <td>-76.964607</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1632.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894202</th>\n",
       "      <td>5004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.553833</td>\n",
       "      <td>34.140911</td>\n",
       "      <td>2.0</td>\n",
       "      <td>625.573181</td>\n",
       "      <td>2.255625e+00</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>23.147533</td>\n",
       "      <td>-6.335686</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>1792.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878350</th>\n",
       "      <td>5814.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.484261</td>\n",
       "      <td>7.983827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.821777</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.983827</td>\n",
       "      <td>98.367348</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>1622.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480729</th>\n",
       "      <td>1884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.410904</td>\n",
       "      <td>2.277636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.172211</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.277636</td>\n",
       "      <td>-72.500000</td>\n",
       "      <td>-76.763123</td>\n",
       "      <td>1547.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361959</th>\n",
       "      <td>3033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.699387</td>\n",
       "      <td>613.164795</td>\n",
       "      <td>38.0</td>\n",
       "      <td>609.370972</td>\n",
       "      <td>3.672803e+01</td>\n",
       "      <td>5.340049</td>\n",
       "      <td>52.407722</td>\n",
       "      <td>3.392983</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1522.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087336</th>\n",
       "      <td>7733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.274147</td>\n",
       "      <td>246.902069</td>\n",
       "      <td>11.0</td>\n",
       "      <td>568.768555</td>\n",
       "      <td>1.244804e+01</td>\n",
       "      <td>2.275502</td>\n",
       "      <td>52.906334</td>\n",
       "      <td>6.802186</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>1652.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315069</th>\n",
       "      <td>6834.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.157318</td>\n",
       "      <td>2.550865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>425.412720</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.550865</td>\n",
       "      <td>41.877541</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>1702.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313943</th>\n",
       "      <td>5387.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.691048</td>\n",
       "      <td>2.922474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>387.539795</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.922474</td>\n",
       "      <td>-0.729188</td>\n",
       "      <td>-17.500000</td>\n",
       "      <td>1692.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10453305 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         i_event  prim          T           E  Size        EToF  EnergyMoment  \\\n",
       "3499177   1731.0   1.0  63.755749  149.914871   6.0  607.207764  6.798460e+00   \n",
       "8869071   3484.0   0.0  74.362877   15.335159   4.0  580.952515  3.743494e+00   \n",
       "2585062   5713.0   0.0  68.605553   37.585819   1.0  600.481689  2.278178e-13   \n",
       "2894202   5004.0   0.0  74.553833   34.140911   2.0  625.573181  2.255625e+00   \n",
       "3878350   5814.0   0.0  86.484261    7.983827   1.0  264.821777  0.000000e+00   \n",
       "...          ...   ...        ...         ...   ...         ...           ...   \n",
       "480729    1884.0   0.0  79.410904    2.277636   1.0  296.172211  0.000000e+00   \n",
       "3361959   3033.0   1.0  63.699387  613.164795  38.0  609.370972  3.672803e+01   \n",
       "7087336   7733.0   0.0  70.274147  246.902069  11.0  568.768555  1.244804e+01   \n",
       "8315069   6834.0   0.0  78.157318    2.550865   1.0  425.412720  0.000000e+00   \n",
       "1313943   5387.0   0.0  79.691048    2.922474   1.0  387.539795  1.110223e-16   \n",
       "\n",
       "           TSpawn    MaxEHit          X          Y       Z  \n",
       "3499177  1.218181  64.293854  -0.682722 -22.500000  1522.5  \n",
       "8869071  0.394498   9.338829  37.500000  -1.970521  1757.5  \n",
       "2585062  0.000000  37.585819 -76.964607   2.500000  1632.5  \n",
       "2894202  0.020336  23.147533  -6.335686  17.500000  1792.5  \n",
       "3878350  0.000000   7.983827  98.367348  67.500000  1622.5  \n",
       "...           ...        ...        ...        ...     ...  \n",
       "480729   0.000000   2.277636 -72.500000 -76.763123  1547.5  \n",
       "3361959  5.340049  52.407722   3.392983  12.500000  1522.5  \n",
       "7087336  2.275502  52.906334   6.802186  37.500000  1652.5  \n",
       "8315069  0.000000   2.550865  41.877541  82.500000  1702.5  \n",
       "1313943  0.000000   2.922474  -0.729188 -17.500000  1692.5  \n",
       "\n",
       "[10453305 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = [filename_for(15, 30, 600, 500, n, \"inclxx\", s, \"clusterfeature.pkl\") for n in [1, 2, 3, 4] for s in range(20)]\n",
    "dfs = [pd.read_pickle(file) for file in files]\n",
    "data = pd.concat(dfs, ignore_index=True).sample(frac=1, random_state=1337)\n",
    "\n",
    "print(data[\"prim\"].value_counts())\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    1782525\n",
      "0.0    1782525\n",
      "Name: prim, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prim1 = data[data[\"prim\"] == 1]\n",
    "prim0 = data[data[\"prim\"] == 0].sample(n=len(prim1.index), random_state=1337)\n",
    "balanced_data = pd.concat([prim0, prim1], ignore_index=True).sample(frac=1, random_state=1337)\n",
    "\n",
    "print(balanced_data[\"prim\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2853700, 12) (711350, 12)\n"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(len(balanced_data)) < 0.8\n",
    "traindata = balanced_data[msk]\n",
    "testdata = balanced_data[~msk]\n",
    "\n",
    "print(traindata.shape, testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"T\", \"E\", \"Size\", \"EToF\", \"EnergyMoment\", \"TSpawn\", \"MaxEHit\", \"X\", \"Y\", \"Z\"]\n",
    "label = [\"prim\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rfc():\n",
    "    defaults = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"criterion\": \"gini\",\n",
    "        \"max_depth\": None,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"min_weight_fraction_leaf\": 0.0,\n",
    "        \"max_features\": \"auto\",\n",
    "        \"max_leaf_nodes\": None,\n",
    "        \"min_impurity_decrease\": 0.0,\n",
    "        \"min_impurity_split\": None,\n",
    "        \"bootstrap\": True,\n",
    "        \"oob_score\": False,\n",
    "        \"n_jobs\": None,\n",
    "        \"random_state\": None,\n",
    "        \"verbose\": 0,\n",
    "        \"warm_start\": False,\n",
    "        \"class_weight\": None,\n",
    "        \"ccp_alpha\": 0.0,\n",
    "        \"max_samples\": None,\n",
    "    }\n",
    "\n",
    "    settings = defaults\n",
    "    settings[\"n_jobs\"] = -1\n",
    "\n",
    "    model = sklearn.ensemble.RandomForestClassifier(**settings)\n",
    "\n",
    "    opt = skopt.BayesSearchCV(\n",
    "        model,\n",
    "        {\n",
    "            \"n_estimators\": skopt.space.Integer(10, 500),  # 0.905 <-> 0.912\n",
    "            # \"criterion\": skopt.space.Categorical([\"gini\", \"entropy\"]),  # almost no difference?\n",
    "            \"min_samples_split\": skopt.space.Integer(2, 5000),\n",
    "            \"min_samples_leaf\": skopt.space.Integer(1, 5000),\n",
    "            # \"min_impurity_decrease\": skopt.space.Real(0.0, 0.5),  # 0 is best\n",
    "        },\n",
    "        n_iter=50,\n",
    "        cv=2,\n",
    "        n_jobs=2,\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    opt.fit(traindata[features], traindata[label].values.ravel())\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = opt.predict(testdata[features])\n",
    "    y_true = testdata[label].values.ravel()\n",
    "    bac = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "    y_pred = opt.predict(data[features])\n",
    "    y_true = data[label].values.ravel()\n",
    "    bacall = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return opt, (\"RandomForestClassifier\", end - start, bac, bacall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RandomForestClassifier', 7985.7673370838165, 0.9132678444597035, 0.9194869097605568)\n",
      "OrderedDict([('min_samples_leaf', 6), ('min_samples_split', 36), ('n_estimators', 61)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.907193</td>\n",
       "      <td>0.908061</td>\n",
       "      <td>0.907627</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>38</td>\n",
       "      <td>34.573221</td>\n",
       "      <td>0.118940</td>\n",
       "      <td>1.430541</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>1160</td>\n",
       "      <td>2100</td>\n",
       "      <td>94</td>\n",
       "      <td>{'min_samples_leaf': 1160, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.904101</td>\n",
       "      <td>0.904620</td>\n",
       "      <td>0.904360</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>43</td>\n",
       "      <td>114.782234</td>\n",
       "      <td>2.559237</td>\n",
       "      <td>4.175770</td>\n",
       "      <td>0.828215</td>\n",
       "      <td>3778</td>\n",
       "      <td>4114</td>\n",
       "      <td>386</td>\n",
       "      <td>{'min_samples_leaf': 3778, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.910536</td>\n",
       "      <td>0.910916</td>\n",
       "      <td>0.910726</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>24</td>\n",
       "      <td>52.098647</td>\n",
       "      <td>0.387210</td>\n",
       "      <td>1.778177</td>\n",
       "      <td>0.138666</td>\n",
       "      <td>65</td>\n",
       "      <td>1529</td>\n",
       "      <td>108</td>\n",
       "      <td>{'min_samples_leaf': 65, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905147</td>\n",
       "      <td>0.905701</td>\n",
       "      <td>0.905424</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>42</td>\n",
       "      <td>128.420776</td>\n",
       "      <td>0.917267</td>\n",
       "      <td>4.305318</td>\n",
       "      <td>0.237132</td>\n",
       "      <td>2780</td>\n",
       "      <td>3836</td>\n",
       "      <td>343</td>\n",
       "      <td>{'min_samples_leaf': 2780, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.908713</td>\n",
       "      <td>0.909276</td>\n",
       "      <td>0.908995</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>32</td>\n",
       "      <td>56.176945</td>\n",
       "      <td>0.271321</td>\n",
       "      <td>1.885463</td>\n",
       "      <td>0.122050</td>\n",
       "      <td>358</td>\n",
       "      <td>4234</td>\n",
       "      <td>120</td>\n",
       "      <td>{'min_samples_leaf': 358, 'min_samples_split':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.903630</td>\n",
       "      <td>0.904565</td>\n",
       "      <td>0.904097</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>44</td>\n",
       "      <td>16.329762</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.954827</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>3668</td>\n",
       "      <td>1275</td>\n",
       "      <td>42</td>\n",
       "      <td>{'min_samples_leaf': 3668, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.906889</td>\n",
       "      <td>0.907332</td>\n",
       "      <td>0.907110</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>39</td>\n",
       "      <td>207.194877</td>\n",
       "      <td>0.324093</td>\n",
       "      <td>7.286741</td>\n",
       "      <td>0.076116</td>\n",
       "      <td>1450</td>\n",
       "      <td>932</td>\n",
       "      <td>491</td>\n",
       "      <td>{'min_samples_leaf': 1450, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.902992</td>\n",
       "      <td>0.903845</td>\n",
       "      <td>0.903418</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>48</td>\n",
       "      <td>128.626661</td>\n",
       "      <td>1.062452</td>\n",
       "      <td>4.310378</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>4986</td>\n",
       "      <td>3602</td>\n",
       "      <td>364</td>\n",
       "      <td>{'min_samples_leaf': 4986, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.905732</td>\n",
       "      <td>0.905856</td>\n",
       "      <td>0.905794</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>41</td>\n",
       "      <td>59.032526</td>\n",
       "      <td>0.977486</td>\n",
       "      <td>1.780278</td>\n",
       "      <td>0.140141</td>\n",
       "      <td>2291</td>\n",
       "      <td>1880</td>\n",
       "      <td>146</td>\n",
       "      <td>{'min_samples_leaf': 2291, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.906553</td>\n",
       "      <td>0.906252</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>40</td>\n",
       "      <td>130.922559</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>4.215229</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>2039</td>\n",
       "      <td>4348</td>\n",
       "      <td>322</td>\n",
       "      <td>{'min_samples_leaf': 2039, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.912258</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.912480</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>10</td>\n",
       "      <td>342.091689</td>\n",
       "      <td>9.382616</td>\n",
       "      <td>20.411077</td>\n",
       "      <td>2.339247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.909026</td>\n",
       "      <td>0.909474</td>\n",
       "      <td>0.909250</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>28</td>\n",
       "      <td>253.617051</td>\n",
       "      <td>1.352335</td>\n",
       "      <td>7.025296</td>\n",
       "      <td>0.474842</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.908736</td>\n",
       "      <td>0.909206</td>\n",
       "      <td>0.908971</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>33</td>\n",
       "      <td>13.098490</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.713561</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>31</td>\n",
       "      <td>4556</td>\n",
       "      <td>23</td>\n",
       "      <td>{'min_samples_leaf': 31, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.912915</td>\n",
       "      <td>0.913310</td>\n",
       "      <td>0.913112</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>2</td>\n",
       "      <td>301.406910</td>\n",
       "      <td>7.776945</td>\n",
       "      <td>11.944759</td>\n",
       "      <td>3.212314</td>\n",
       "      <td>7</td>\n",
       "      <td>132</td>\n",
       "      <td>490</td>\n",
       "      <td>{'min_samples_leaf': 7, 'min_samples_split': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.912532</td>\n",
       "      <td>0.912782</td>\n",
       "      <td>0.912657</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>5</td>\n",
       "      <td>279.561017</td>\n",
       "      <td>1.430600</td>\n",
       "      <td>12.152970</td>\n",
       "      <td>0.091224</td>\n",
       "      <td>48</td>\n",
       "      <td>111</td>\n",
       "      <td>485</td>\n",
       "      <td>{'min_samples_leaf': 48, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.912269</td>\n",
       "      <td>0.912649</td>\n",
       "      <td>0.912459</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>14</td>\n",
       "      <td>340.565044</td>\n",
       "      <td>0.544134</td>\n",
       "      <td>31.783124</td>\n",
       "      <td>0.619334</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.912254</td>\n",
       "      <td>0.912700</td>\n",
       "      <td>0.912477</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>11</td>\n",
       "      <td>344.024683</td>\n",
       "      <td>4.297233</td>\n",
       "      <td>25.740458</td>\n",
       "      <td>0.270815</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.908723</td>\n",
       "      <td>0.908937</td>\n",
       "      <td>0.908830</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>35</td>\n",
       "      <td>9.684348</td>\n",
       "      <td>0.181645</td>\n",
       "      <td>0.638307</td>\n",
       "      <td>0.043264</td>\n",
       "      <td>26</td>\n",
       "      <td>4919</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 26, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.903257</td>\n",
       "      <td>0.903939</td>\n",
       "      <td>0.903598</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>46</td>\n",
       "      <td>18.873512</td>\n",
       "      <td>0.806222</td>\n",
       "      <td>0.897765</td>\n",
       "      <td>0.085855</td>\n",
       "      <td>4866</td>\n",
       "      <td>81</td>\n",
       "      <td>53</td>\n",
       "      <td>{'min_samples_leaf': 4866, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.912410</td>\n",
       "      <td>0.912694</td>\n",
       "      <td>0.912552</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>6</td>\n",
       "      <td>24.348874</td>\n",
       "      <td>0.039298</td>\n",
       "      <td>1.506779</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>{'min_samples_leaf': 46, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.908972</td>\n",
       "      <td>0.909440</td>\n",
       "      <td>0.909206</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>30</td>\n",
       "      <td>235.314655</td>\n",
       "      <td>0.123590</td>\n",
       "      <td>7.586354</td>\n",
       "      <td>0.224753</td>\n",
       "      <td>80</td>\n",
       "      <td>4985</td>\n",
       "      <td>499</td>\n",
       "      <td>{'min_samples_leaf': 80, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.912216</td>\n",
       "      <td>0.912542</td>\n",
       "      <td>0.912379</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>19</td>\n",
       "      <td>345.309897</td>\n",
       "      <td>9.730320</td>\n",
       "      <td>19.510868</td>\n",
       "      <td>2.881572</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.911837</td>\n",
       "      <td>0.912176</td>\n",
       "      <td>0.912006</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>20</td>\n",
       "      <td>17.754072</td>\n",
       "      <td>0.286201</td>\n",
       "      <td>1.080380</td>\n",
       "      <td>0.042536</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>31</td>\n",
       "      <td>{'min_samples_leaf': 87, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.912199</td>\n",
       "      <td>0.912651</td>\n",
       "      <td>0.912425</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>16</td>\n",
       "      <td>344.206447</td>\n",
       "      <td>5.030058</td>\n",
       "      <td>24.851644</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.912209</td>\n",
       "      <td>0.912617</td>\n",
       "      <td>0.912413</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>18</td>\n",
       "      <td>345.233032</td>\n",
       "      <td>7.060791</td>\n",
       "      <td>23.917055</td>\n",
       "      <td>0.808893</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.912331</td>\n",
       "      <td>0.912676</td>\n",
       "      <td>0.912504</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>8</td>\n",
       "      <td>344.618447</td>\n",
       "      <td>1.194424</td>\n",
       "      <td>30.525107</td>\n",
       "      <td>0.259157</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.908550</td>\n",
       "      <td>0.909069</td>\n",
       "      <td>0.908810</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>36</td>\n",
       "      <td>10.269160</td>\n",
       "      <td>0.118089</td>\n",
       "      <td>0.642821</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>59</td>\n",
       "      <td>4902</td>\n",
       "      <td>16</td>\n",
       "      <td>{'min_samples_leaf': 59, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.903184</td>\n",
       "      <td>0.904030</td>\n",
       "      <td>0.903607</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>45</td>\n",
       "      <td>172.362169</td>\n",
       "      <td>5.495486</td>\n",
       "      <td>7.324860</td>\n",
       "      <td>2.761125</td>\n",
       "      <td>4887</td>\n",
       "      <td>45</td>\n",
       "      <td>496</td>\n",
       "      <td>{'min_samples_leaf': 4887, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.912977</td>\n",
       "      <td>0.913331</td>\n",
       "      <td>0.913154</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1</td>\n",
       "      <td>43.536865</td>\n",
       "      <td>0.563055</td>\n",
       "      <td>2.270723</td>\n",
       "      <td>0.202263</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>{'min_samples_leaf': 6, 'min_samples_split': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.912274</td>\n",
       "      <td>0.912631</td>\n",
       "      <td>0.912452</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>15</td>\n",
       "      <td>347.415612</td>\n",
       "      <td>5.963040</td>\n",
       "      <td>23.343082</td>\n",
       "      <td>1.270948</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.912363</td>\n",
       "      <td>0.912640</td>\n",
       "      <td>0.912501</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>9</td>\n",
       "      <td>22.893966</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>1.521641</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>{'min_samples_leaf': 50, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.908921</td>\n",
       "      <td>0.909285</td>\n",
       "      <td>0.909103</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>31</td>\n",
       "      <td>220.630601</td>\n",
       "      <td>2.552236</td>\n",
       "      <td>5.393334</td>\n",
       "      <td>0.519526</td>\n",
       "      <td>163</td>\n",
       "      <td>4935</td>\n",
       "      <td>472</td>\n",
       "      <td>{'min_samples_leaf': 163, 'min_samples_split':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.908972</td>\n",
       "      <td>0.909535</td>\n",
       "      <td>0.909254</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>27</td>\n",
       "      <td>238.728845</td>\n",
       "      <td>2.877553</td>\n",
       "      <td>5.355047</td>\n",
       "      <td>0.596749</td>\n",
       "      <td>36</td>\n",
       "      <td>4885</td>\n",
       "      <td>492</td>\n",
       "      <td>{'min_samples_leaf': 36, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.912455</td>\n",
       "      <td>0.912646</td>\n",
       "      <td>0.912551</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>7</td>\n",
       "      <td>15.097809</td>\n",
       "      <td>0.173297</td>\n",
       "      <td>1.034973</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
       "      <td>21</td>\n",
       "      <td>{'min_samples_leaf': 7, 'min_samples_split': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.902946</td>\n",
       "      <td>0.903841</td>\n",
       "      <td>0.903394</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>49</td>\n",
       "      <td>9.800402</td>\n",
       "      <td>0.035670</td>\n",
       "      <td>0.601071</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>4953</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>{'min_samples_leaf': 4953, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.908731</td>\n",
       "      <td>0.909041</td>\n",
       "      <td>0.908886</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>34</td>\n",
       "      <td>18.791543</td>\n",
       "      <td>0.140773</td>\n",
       "      <td>0.886886</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>49</td>\n",
       "      <td>4809</td>\n",
       "      <td>38</td>\n",
       "      <td>{'min_samples_leaf': 49, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.912232</td>\n",
       "      <td>0.912611</td>\n",
       "      <td>0.912421</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>17</td>\n",
       "      <td>346.323101</td>\n",
       "      <td>10.774824</td>\n",
       "      <td>19.673479</td>\n",
       "      <td>2.401518</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.912467</td>\n",
       "      <td>0.912946</td>\n",
       "      <td>0.912706</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>3</td>\n",
       "      <td>20.295426</td>\n",
       "      <td>0.341058</td>\n",
       "      <td>1.030032</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>33</td>\n",
       "      <td>75</td>\n",
       "      <td>33</td>\n",
       "      <td>{'min_samples_leaf': 33, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.912246</td>\n",
       "      <td>0.912682</td>\n",
       "      <td>0.912464</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>13</td>\n",
       "      <td>343.083179</td>\n",
       "      <td>5.118267</td>\n",
       "      <td>26.679225</td>\n",
       "      <td>0.594509</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.903361</td>\n",
       "      <td>0.903785</td>\n",
       "      <td>0.903573</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>47</td>\n",
       "      <td>165.675446</td>\n",
       "      <td>3.708678</td>\n",
       "      <td>6.057712</td>\n",
       "      <td>1.503177</td>\n",
       "      <td>4950</td>\n",
       "      <td>111</td>\n",
       "      <td>473</td>\n",
       "      <td>{'min_samples_leaf': 4950, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.910581</td>\n",
       "      <td>0.910735</td>\n",
       "      <td>0.910658</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>25</td>\n",
       "      <td>9.731462</td>\n",
       "      <td>0.071707</td>\n",
       "      <td>0.618665</td>\n",
       "      <td>0.018964</td>\n",
       "      <td>220</td>\n",
       "      <td>119</td>\n",
       "      <td>12</td>\n",
       "      <td>{'min_samples_leaf': 220, 'min_samples_split':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.912249</td>\n",
       "      <td>0.912690</td>\n",
       "      <td>0.912469</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>12</td>\n",
       "      <td>344.275541</td>\n",
       "      <td>7.533504</td>\n",
       "      <td>22.272629</td>\n",
       "      <td>0.697661</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.911395</td>\n",
       "      <td>0.911850</td>\n",
       "      <td>0.911622</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>23</td>\n",
       "      <td>9.436622</td>\n",
       "      <td>0.371657</td>\n",
       "      <td>0.699391</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>97</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>{'min_samples_leaf': 97, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.909006</td>\n",
       "      <td>0.909431</td>\n",
       "      <td>0.909218</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>29</td>\n",
       "      <td>227.743930</td>\n",
       "      <td>2.668842</td>\n",
       "      <td>5.328354</td>\n",
       "      <td>0.348680</td>\n",
       "      <td>70</td>\n",
       "      <td>4897</td>\n",
       "      <td>480</td>\n",
       "      <td>{'min_samples_leaf': 70, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.908428</td>\n",
       "      <td>0.908919</td>\n",
       "      <td>0.908673</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>37</td>\n",
       "      <td>12.389406</td>\n",
       "      <td>0.169724</td>\n",
       "      <td>0.654914</td>\n",
       "      <td>0.054248</td>\n",
       "      <td>55</td>\n",
       "      <td>4986</td>\n",
       "      <td>22</td>\n",
       "      <td>{'min_samples_leaf': 55, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.908990</td>\n",
       "      <td>0.909520</td>\n",
       "      <td>0.909255</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>26</td>\n",
       "      <td>240.691578</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>6.695626</td>\n",
       "      <td>0.478386</td>\n",
       "      <td>6</td>\n",
       "      <td>4944</td>\n",
       "      <td>482</td>\n",
       "      <td>{'min_samples_leaf': 6, 'min_samples_split': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.912507</td>\n",
       "      <td>0.912817</td>\n",
       "      <td>0.912662</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>4</td>\n",
       "      <td>31.439536</td>\n",
       "      <td>0.712414</td>\n",
       "      <td>1.324066</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>{'min_samples_leaf': 41, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.911820</td>\n",
       "      <td>0.912119</td>\n",
       "      <td>0.911969</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>21</td>\n",
       "      <td>11.774973</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.867722</td>\n",
       "      <td>0.044435</td>\n",
       "      <td>60</td>\n",
       "      <td>206</td>\n",
       "      <td>17</td>\n",
       "      <td>{'min_samples_leaf': 60, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.902275</td>\n",
       "      <td>0.903850</td>\n",
       "      <td>0.903063</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>50</td>\n",
       "      <td>13.550010</td>\n",
       "      <td>0.129987</td>\n",
       "      <td>0.786872</td>\n",
       "      <td>0.037369</td>\n",
       "      <td>4959</td>\n",
       "      <td>103</td>\n",
       "      <td>37</td>\n",
       "      <td>{'min_samples_leaf': 4959, 'min_samples_split'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.911755</td>\n",
       "      <td>0.911930</td>\n",
       "      <td>0.911843</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>22</td>\n",
       "      <td>12.700445</td>\n",
       "      <td>0.226739</td>\n",
       "      <td>0.870562</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>83</td>\n",
       "      <td>163</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 83, 'min_samples_split': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.907193           0.908061         0.907627        0.000434   \n",
       "1            0.904101           0.904620         0.904360        0.000260   \n",
       "2            0.910536           0.910916         0.910726        0.000190   \n",
       "3            0.905147           0.905701         0.905424        0.000277   \n",
       "4            0.908713           0.909276         0.908995        0.000282   \n",
       "5            0.903630           0.904565         0.904097        0.000468   \n",
       "6            0.906889           0.907332         0.907110        0.000221   \n",
       "7            0.902992           0.903845         0.903418        0.000426   \n",
       "8            0.905732           0.905856         0.905794        0.000062   \n",
       "9            0.905952           0.906553         0.906252        0.000301   \n",
       "10           0.912258           0.912703         0.912480        0.000223   \n",
       "11           0.909026           0.909474         0.909250        0.000224   \n",
       "12           0.908736           0.909206         0.908971        0.000235   \n",
       "13           0.912915           0.913310         0.913112        0.000197   \n",
       "14           0.912532           0.912782         0.912657        0.000125   \n",
       "15           0.912269           0.912649         0.912459        0.000190   \n",
       "16           0.912254           0.912700         0.912477        0.000223   \n",
       "17           0.908723           0.908937         0.908830        0.000107   \n",
       "18           0.903257           0.903939         0.903598        0.000341   \n",
       "19           0.912410           0.912694         0.912552        0.000142   \n",
       "20           0.908972           0.909440         0.909206        0.000234   \n",
       "21           0.912216           0.912542         0.912379        0.000163   \n",
       "22           0.911837           0.912176         0.912006        0.000170   \n",
       "23           0.912199           0.912651         0.912425        0.000226   \n",
       "24           0.912209           0.912617         0.912413        0.000204   \n",
       "25           0.912331           0.912676         0.912504        0.000172   \n",
       "26           0.908550           0.909069         0.908810        0.000259   \n",
       "27           0.903184           0.904030         0.903607        0.000423   \n",
       "28           0.912977           0.913331         0.913154        0.000177   \n",
       "29           0.912274           0.912631         0.912452        0.000178   \n",
       "30           0.912363           0.912640         0.912501        0.000138   \n",
       "31           0.908921           0.909285         0.909103        0.000182   \n",
       "32           0.908972           0.909535         0.909254        0.000281   \n",
       "33           0.912455           0.912646         0.912551        0.000095   \n",
       "34           0.902946           0.903841         0.903394        0.000447   \n",
       "35           0.908731           0.909041         0.908886        0.000155   \n",
       "36           0.912232           0.912611         0.912421        0.000190   \n",
       "37           0.912467           0.912946         0.912706        0.000240   \n",
       "38           0.912246           0.912682         0.912464        0.000218   \n",
       "39           0.903361           0.903785         0.903573        0.000212   \n",
       "40           0.910581           0.910735         0.910658        0.000077   \n",
       "41           0.912249           0.912690         0.912469        0.000221   \n",
       "42           0.911395           0.911850         0.911622        0.000227   \n",
       "43           0.909006           0.909431         0.909218        0.000212   \n",
       "44           0.908428           0.908919         0.908673        0.000246   \n",
       "45           0.908990           0.909520         0.909255        0.000265   \n",
       "46           0.912507           0.912817         0.912662        0.000155   \n",
       "47           0.911820           0.912119         0.911969        0.000150   \n",
       "48           0.902275           0.903850         0.903063        0.000788   \n",
       "49           0.911755           0.911930         0.911843        0.000087   \n",
       "\n",
       "    rank_test_score  mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "0                38      34.573221      0.118940         1.430541   \n",
       "1                43     114.782234      2.559237         4.175770   \n",
       "2                24      52.098647      0.387210         1.778177   \n",
       "3                42     128.420776      0.917267         4.305318   \n",
       "4                32      56.176945      0.271321         1.885463   \n",
       "5                44      16.329762      0.007211         0.954827   \n",
       "6                39     207.194877      0.324093         7.286741   \n",
       "7                48     128.626661      1.062452         4.310378   \n",
       "8                41      59.032526      0.977486         1.780278   \n",
       "9                40     130.922559      0.783307         4.215229   \n",
       "10               10     342.091689      9.382616        20.411077   \n",
       "11               28     253.617051      1.352335         7.025296   \n",
       "12               33      13.098490      0.004087         0.713561   \n",
       "13                2     301.406910      7.776945        11.944759   \n",
       "14                5     279.561017      1.430600        12.152970   \n",
       "15               14     340.565044      0.544134        31.783124   \n",
       "16               11     344.024683      4.297233        25.740458   \n",
       "17               35       9.684348      0.181645         0.638307   \n",
       "18               46      18.873512      0.806222         0.897765   \n",
       "19                6      24.348874      0.039298         1.506779   \n",
       "20               30     235.314655      0.123590         7.586354   \n",
       "21               19     345.309897      9.730320        19.510868   \n",
       "22               20      17.754072      0.286201         1.080380   \n",
       "23               16     344.206447      5.030058        24.851644   \n",
       "24               18     345.233032      7.060791        23.917055   \n",
       "25                8     344.618447      1.194424        30.525107   \n",
       "26               36      10.269160      0.118089         0.642821   \n",
       "27               45     172.362169      5.495486         7.324860   \n",
       "28                1      43.536865      0.563055         2.270723   \n",
       "29               15     347.415612      5.963040        23.343082   \n",
       "30                9      22.893966      0.002164         1.521641   \n",
       "31               31     220.630601      2.552236         5.393334   \n",
       "32               27     238.728845      2.877553         5.355047   \n",
       "33                7      15.097809      0.173297         1.034973   \n",
       "34               49       9.800402      0.035670         0.601071   \n",
       "35               34      18.791543      0.140773         0.886886   \n",
       "36               17     346.323101     10.774824        19.673479   \n",
       "37                3      20.295426      0.341058         1.030032   \n",
       "38               13     343.083179      5.118267        26.679225   \n",
       "39               47     165.675446      3.708678         6.057712   \n",
       "40               25       9.731462      0.071707         0.618665   \n",
       "41               12     344.275541      7.533504        22.272629   \n",
       "42               23       9.436622      0.371657         0.699391   \n",
       "43               29     227.743930      2.668842         5.328354   \n",
       "44               37      12.389406      0.169724         0.654914   \n",
       "45               26     240.691578      0.695590         6.695626   \n",
       "46                4      31.439536      0.712414         1.324066   \n",
       "47               21      11.774973      0.019967         0.867722   \n",
       "48               50      13.550010      0.129987         0.786872   \n",
       "49               22      12.700445      0.226739         0.870562   \n",
       "\n",
       "    std_score_time  param_min_samples_leaf  param_min_samples_split  \\\n",
       "0         0.019465                    1160                     2100   \n",
       "1         0.828215                    3778                     4114   \n",
       "2         0.138666                      65                     1529   \n",
       "3         0.237132                    2780                     3836   \n",
       "4         0.122050                     358                     4234   \n",
       "5         0.010155                    3668                     1275   \n",
       "6         0.076116                    1450                      932   \n",
       "7         0.240939                    4986                     3602   \n",
       "8         0.140141                    2291                     1880   \n",
       "9         0.066467                    2039                     4348   \n",
       "10        2.339247                       1                        2   \n",
       "11        0.474842                       1                     5000   \n",
       "12        0.006220                      31                     4556   \n",
       "13        3.212314                       7                      132   \n",
       "14        0.091224                      48                      111   \n",
       "15        0.619334                       1                        2   \n",
       "16        0.270815                       1                        2   \n",
       "17        0.043264                      26                     4919   \n",
       "18        0.085855                    4866                       81   \n",
       "19        0.006333                      46                       23   \n",
       "20        0.224753                      80                     4985   \n",
       "21        2.881572                       1                        2   \n",
       "22        0.042536                      87                       90   \n",
       "23        0.042688                       1                        2   \n",
       "24        0.808893                       1                        2   \n",
       "25        0.259157                       1                        2   \n",
       "26        0.025756                      59                     4902   \n",
       "27        2.761125                    4887                       45   \n",
       "28        0.202263                       6                       36   \n",
       "29        1.270948                       1                        2   \n",
       "30        0.015388                      50                       39   \n",
       "31        0.519526                     163                     4935   \n",
       "32        0.596749                      36                     4885   \n",
       "33        0.036123                       7                      187   \n",
       "34        0.002759                    4953                       58   \n",
       "35        0.041236                      49                     4809   \n",
       "36        2.401518                       1                        2   \n",
       "37        0.025397                      33                       75   \n",
       "38        0.594509                       1                        2   \n",
       "39        1.503177                    4950                      111   \n",
       "40        0.018964                     220                      119   \n",
       "41        0.697661                       1                        2   \n",
       "42        0.002092                      97                       21   \n",
       "43        0.348680                      70                     4897   \n",
       "44        0.054248                      55                     4986   \n",
       "45        0.478386                       6                     4944   \n",
       "46        0.004697                      41                       33   \n",
       "47        0.044435                      60                      206   \n",
       "48        0.037369                    4959                      103   \n",
       "49        0.033299                      83                      163   \n",
       "\n",
       "    param_n_estimators                                             params  \n",
       "0                   94  {'min_samples_leaf': 1160, 'min_samples_split'...  \n",
       "1                  386  {'min_samples_leaf': 3778, 'min_samples_split'...  \n",
       "2                  108  {'min_samples_leaf': 65, 'min_samples_split': ...  \n",
       "3                  343  {'min_samples_leaf': 2780, 'min_samples_split'...  \n",
       "4                  120  {'min_samples_leaf': 358, 'min_samples_split':...  \n",
       "5                   42  {'min_samples_leaf': 3668, 'min_samples_split'...  \n",
       "6                  491  {'min_samples_leaf': 1450, 'min_samples_split'...  \n",
       "7                  364  {'min_samples_leaf': 4986, 'min_samples_split'...  \n",
       "8                  146  {'min_samples_leaf': 2291, 'min_samples_split'...  \n",
       "9                  322  {'min_samples_leaf': 2039, 'min_samples_split'...  \n",
       "10                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "11                 500  {'min_samples_leaf': 1, 'min_samples_split': 5...  \n",
       "12                  23  {'min_samples_leaf': 31, 'min_samples_split': ...  \n",
       "13                 490  {'min_samples_leaf': 7, 'min_samples_split': 1...  \n",
       "14                 485  {'min_samples_leaf': 48, 'min_samples_split': ...  \n",
       "15                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "16                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "17                  15  {'min_samples_leaf': 26, 'min_samples_split': ...  \n",
       "18                  53  {'min_samples_leaf': 4866, 'min_samples_split'...  \n",
       "19                  41  {'min_samples_leaf': 46, 'min_samples_split': ...  \n",
       "20                 499  {'min_samples_leaf': 80, 'min_samples_split': ...  \n",
       "21                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "22                  31  {'min_samples_leaf': 87, 'min_samples_split': ...  \n",
       "23                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "24                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "25                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "26                  16  {'min_samples_leaf': 59, 'min_samples_split': ...  \n",
       "27                 496  {'min_samples_leaf': 4887, 'min_samples_split'...  \n",
       "28                  61  {'min_samples_leaf': 6, 'min_samples_split': 3...  \n",
       "29                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "30                  39  {'min_samples_leaf': 50, 'min_samples_split': ...  \n",
       "31                 472  {'min_samples_leaf': 163, 'min_samples_split':...  \n",
       "32                 492  {'min_samples_leaf': 36, 'min_samples_split': ...  \n",
       "33                  21  {'min_samples_leaf': 7, 'min_samples_split': 1...  \n",
       "34                  24  {'min_samples_leaf': 4953, 'min_samples_split'...  \n",
       "35                  38  {'min_samples_leaf': 49, 'min_samples_split': ...  \n",
       "36                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "37                  33  {'min_samples_leaf': 33, 'min_samples_split': ...  \n",
       "38                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "39                 473  {'min_samples_leaf': 4950, 'min_samples_split'...  \n",
       "40                  12  {'min_samples_leaf': 220, 'min_samples_split':...  \n",
       "41                 500  {'min_samples_leaf': 1, 'min_samples_split': 2...  \n",
       "42                  12  {'min_samples_leaf': 97, 'min_samples_split': ...  \n",
       "43                 480  {'min_samples_leaf': 70, 'min_samples_split': ...  \n",
       "44                  22  {'min_samples_leaf': 55, 'min_samples_split': ...  \n",
       "45                 482  {'min_samples_leaf': 6, 'min_samples_split': 4...  \n",
       "46                  52  {'min_samples_leaf': 41, 'min_samples_split': ...  \n",
       "47                  17  {'min_samples_leaf': 60, 'min_samples_split': ...  \n",
       "48                  37  {'min_samples_leaf': 4959, 'min_samples_split'...  \n",
       "49                  20  {'min_samples_leaf': 83, 'min_samples_split': ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc_opt, rfc_result = optimize_rfc()\n",
    "print(rfc_result)\n",
    "print(rfc_opt.best_params_)\n",
    "display(pd.DataFrame(rfc_opt.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skopt not doing the best job here? Try manual\n",
    "def optimize_mpl(layers=(100,)):\n",
    "    defaults = {\n",
    "        \"hidden_layer_sizes\": (100,),\n",
    "        \"activation\": \"relu\",\n",
    "        \"solver\": \"adam\",\n",
    "        \"alpha\": 0.0001,\n",
    "        \"batch_size\": \"auto\",\n",
    "        \"learning_rate\": \"constant\",\n",
    "        \"learning_rate_init\": 0.001,\n",
    "        \"power_t\": 0.5,\n",
    "        \"max_iter\": 200,\n",
    "        \"shuffle\": True,\n",
    "        \"random_state\": None,\n",
    "        \"tol\": 0.0001,\n",
    "        \"verbose\": False,\n",
    "        \"warm_start\": False,\n",
    "        \"momentum\": 0.9,\n",
    "        \"nesterovs_momentum\": True,\n",
    "        \"early_stopping\": False,\n",
    "        \"validation_fraction\": 0.1,\n",
    "        \"beta_1\": 0.9,\n",
    "        \"beta_2\": 0.999,\n",
    "        \"epsilon\": 1e-08,\n",
    "        \"n_iter_no_change\": 10,\n",
    "        \"max_fun\": 15000,\n",
    "    }\n",
    "\n",
    "    settings = defaults\n",
    "    settings[\"hidden_layer_sizes\"] = layers\n",
    "    settings[\"learning_rate\"] = \"adaptive\"\n",
    "    settings[\"early_stopping\"] = True\n",
    "    settings[\"validation_fraction\"] = 0.2\n",
    "\n",
    "    model = sklearn.neural_network.MLPClassifier(**settings)\n",
    "\n",
    "    train_size = 500000\n",
    "    x_train = traindata[:train_size][features]\n",
    "    y_train = traindata[:train_size][label].values.ravel()\n",
    "\n",
    "    x_test = testdata[features]\n",
    "    y_test = testdata[label].values.ravel()\n",
    "\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    bac = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "    return (\"MPL-\" + str(layers), bac, end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in [\n",
    "    (50,),\n",
    "    (100,),\n",
    "    (200,),\n",
    "    (500,),\n",
    "    (50, 25),\n",
    "    (50, 50),\n",
    "    (100, 50),\n",
    "    (200, 25),\n",
    "    (500, 50),\n",
    "]:\n",
    "    result = optimize_mpl(layer)\n",
    "    print(result)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: PAC gives very different results for different random_state -> Disqualify?\n",
    "#       this might explain difference between scalers\n",
    "# Note: skopt produces some strange errors here ...\n",
    "# Optimize:\n",
    "#   fit_intercept=True/False -> No difference\n",
    "#   loss=\"hinge\"/\"squared_hinge\" -> No difference\n",
    "def optimize_pac():\n",
    "    x_train = traindata[features]\n",
    "    y_train = traindata[label].values.ravel()\n",
    "\n",
    "    x_test = testdata[features]\n",
    "    y_test = testdata[label].values.ravel()\n",
    "\n",
    "    model = sklearn.linear_model.PassiveAggressiveClassifier(\n",
    "        max_iter=10000, tol=1e-6, n_jobs=-1, warm_start=False, class_weight=\"balanced\", random_state=1337,\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    bac = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "    return (\"PAC\", bac, end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize_pac()\n",
    "print(result)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n",
      "/home/jmayer/.pyenv/versions/3.7.6/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py:294: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658.5892052650452 0.8774374919254401\n",
      "OrderedDict([('alpha', 1e-05), ('eta0', 0.75), ('fit_intercept', True), ('penalty', 'elasticnet')])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.763602</td>\n",
       "      <td>0.687288</td>\n",
       "      <td>0.189770</td>\n",
       "      <td>0.234003</td>\n",
       "      <td>0.197109</td>\n",
       "      <td>0.212809</td>\n",
       "      <td>0.230172</td>\n",
       "      <td>0.683535</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>11.959903</td>\n",
       "      <td>0.646242</td>\n",
       "      <td>0.120364</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.001, 'eta0': 0.25, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.901243</td>\n",
       "      <td>0.881711</td>\n",
       "      <td>0.838720</td>\n",
       "      <td>0.878828</td>\n",
       "      <td>0.454211</td>\n",
       "      <td>0.905782</td>\n",
       "      <td>0.455332</td>\n",
       "      <td>0.781880</td>\n",
       "      <td>0.886389</td>\n",
       "      <td>0.782781</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>15.527935</td>\n",
       "      <td>1.557045</td>\n",
       "      <td>0.117550</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.903315</td>\n",
       "      <td>0.900577</td>\n",
       "      <td>0.895822</td>\n",
       "      <td>0.865751</td>\n",
       "      <td>0.884610</td>\n",
       "      <td>0.866291</td>\n",
       "      <td>0.875176</td>\n",
       "      <td>0.812621</td>\n",
       "      <td>0.894092</td>\n",
       "      <td>0.892417</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>14.198939</td>\n",
       "      <td>2.010234</td>\n",
       "      <td>0.111264</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.829477</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.170520</td>\n",
       "      <td>0.170520</td>\n",
       "      <td>0.829276</td>\n",
       "      <td>0.170522</td>\n",
       "      <td>0.829135</td>\n",
       "      <td>0.829478</td>\n",
       "      <td>0.829414</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>16.012708</td>\n",
       "      <td>2.023319</td>\n",
       "      <td>0.107845</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'eta0': 0.5, 'fit_intercept': T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905102</td>\n",
       "      <td>0.904069</td>\n",
       "      <td>0.828610</td>\n",
       "      <td>0.881810</td>\n",
       "      <td>0.888196</td>\n",
       "      <td>0.892420</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>0.693658</td>\n",
       "      <td>0.901210</td>\n",
       "      <td>0.844484</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>15.772808</td>\n",
       "      <td>1.689184</td>\n",
       "      <td>0.106211</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'eta0': 1.0, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.629873</td>\n",
       "      <td>0.717537</td>\n",
       "      <td>0.822134</td>\n",
       "      <td>0.864994</td>\n",
       "      <td>0.874124</td>\n",
       "      <td>0.469429</td>\n",
       "      <td>0.508499</td>\n",
       "      <td>0.461719</td>\n",
       "      <td>0.516458</td>\n",
       "      <td>0.540114</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>12.006777</td>\n",
       "      <td>0.970923</td>\n",
       "      <td>0.111023</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.1, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.831527</td>\n",
       "      <td>0.871016</td>\n",
       "      <td>0.886255</td>\n",
       "      <td>0.181048</td>\n",
       "      <td>0.170523</td>\n",
       "      <td>0.189064</td>\n",
       "      <td>0.170549</td>\n",
       "      <td>0.830070</td>\n",
       "      <td>0.182337</td>\n",
       "      <td>0.837804</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>15.774977</td>\n",
       "      <td>2.575142</td>\n",
       "      <td>0.107176</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'eta0': 0.5, 'fit_intercept': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.902616</td>\n",
       "      <td>0.617659</td>\n",
       "      <td>0.814985</td>\n",
       "      <td>0.905607</td>\n",
       "      <td>0.886123</td>\n",
       "      <td>0.315340</td>\n",
       "      <td>0.872992</td>\n",
       "      <td>0.672438</td>\n",
       "      <td>0.896124</td>\n",
       "      <td>0.894976</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>16.973424</td>\n",
       "      <td>2.534266</td>\n",
       "      <td>0.107158</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 1.0, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.901922</td>\n",
       "      <td>0.902411</td>\n",
       "      <td>0.505266</td>\n",
       "      <td>0.904858</td>\n",
       "      <td>0.891052</td>\n",
       "      <td>0.753601</td>\n",
       "      <td>0.877707</td>\n",
       "      <td>0.349536</td>\n",
       "      <td>0.899536</td>\n",
       "      <td>0.903790</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>13.041293</td>\n",
       "      <td>1.758001</td>\n",
       "      <td>0.107910</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.707994</td>\n",
       "      <td>0.692316</td>\n",
       "      <td>0.591745</td>\n",
       "      <td>0.878828</td>\n",
       "      <td>0.411619</td>\n",
       "      <td>0.482024</td>\n",
       "      <td>0.525583</td>\n",
       "      <td>0.477180</td>\n",
       "      <td>0.889934</td>\n",
       "      <td>0.527056</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>12.577323</td>\n",
       "      <td>1.453766</td>\n",
       "      <td>0.110008</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.25, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.853347</td>\n",
       "      <td>0.862314</td>\n",
       "      <td>0.211975</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.170520</td>\n",
       "      <td>0.331443</td>\n",
       "      <td>0.843843</td>\n",
       "      <td>0.838493</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.842591</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>15.059484</td>\n",
       "      <td>4.926035</td>\n",
       "      <td>0.105191</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.001, 'eta0': 1.0, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.889113</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.829480</td>\n",
       "      <td>0.829618</td>\n",
       "      <td>0.170520</td>\n",
       "      <td>0.883136</td>\n",
       "      <td>0.178352</td>\n",
       "      <td>0.829966</td>\n",
       "      <td>0.874272</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>17.162330</td>\n",
       "      <td>3.169464</td>\n",
       "      <td>0.103798</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'eta0': 0.75, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.803998</td>\n",
       "      <td>0.904069</td>\n",
       "      <td>0.823931</td>\n",
       "      <td>0.893651</td>\n",
       "      <td>0.707838</td>\n",
       "      <td>0.902996</td>\n",
       "      <td>0.707103</td>\n",
       "      <td>0.693658</td>\n",
       "      <td>0.903248</td>\n",
       "      <td>0.844484</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>13.886246</td>\n",
       "      <td>1.193946</td>\n",
       "      <td>0.109636</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'eta0': 0.25, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.803998</td>\n",
       "      <td>0.904069</td>\n",
       "      <td>0.828610</td>\n",
       "      <td>0.893651</td>\n",
       "      <td>0.707838</td>\n",
       "      <td>0.892420</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>0.693658</td>\n",
       "      <td>0.903248</td>\n",
       "      <td>0.844484</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>15.073264</td>\n",
       "      <td>2.085024</td>\n",
       "      <td>0.106207</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'eta0': 0.5, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.904979</td>\n",
       "      <td>0.828142</td>\n",
       "      <td>0.904133</td>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.894301</td>\n",
       "      <td>0.704747</td>\n",
       "      <td>0.871060</td>\n",
       "      <td>0.721880</td>\n",
       "      <td>0.670290</td>\n",
       "      <td>0.839478</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>15.643414</td>\n",
       "      <td>2.527428</td>\n",
       "      <td>0.107513</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.744939</td>\n",
       "      <td>0.778259</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.241191</td>\n",
       "      <td>0.285376</td>\n",
       "      <td>0.439782</td>\n",
       "      <td>0.439954</td>\n",
       "      <td>0.828969</td>\n",
       "      <td>0.411797</td>\n",
       "      <td>0.781282</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>14.578692</td>\n",
       "      <td>3.372017</td>\n",
       "      <td>0.111036</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'eta0': 0.75, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.735819</td>\n",
       "      <td>0.334921</td>\n",
       "      <td>0.807248</td>\n",
       "      <td>0.898124</td>\n",
       "      <td>0.713673</td>\n",
       "      <td>0.703534</td>\n",
       "      <td>0.902329</td>\n",
       "      <td>0.693035</td>\n",
       "      <td>0.676169</td>\n",
       "      <td>0.845742</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>13.466042</td>\n",
       "      <td>1.345153</td>\n",
       "      <td>0.113425</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'eta0': 0.1, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.343829</td>\n",
       "      <td>0.848469</td>\n",
       "      <td>0.506693</td>\n",
       "      <td>0.895635</td>\n",
       "      <td>0.886212</td>\n",
       "      <td>0.372121</td>\n",
       "      <td>0.871092</td>\n",
       "      <td>0.905056</td>\n",
       "      <td>0.902349</td>\n",
       "      <td>0.904152</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>12.400085</td>\n",
       "      <td>2.056384</td>\n",
       "      <td>0.108575</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.25, 'fit_intercept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.678071</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.841473</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.390362</td>\n",
       "      <td>0.431482</td>\n",
       "      <td>0.448803</td>\n",
       "      <td>0.445665</td>\n",
       "      <td>0.484933</td>\n",
       "      <td>0.447014</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>12.408493</td>\n",
       "      <td>1.164491</td>\n",
       "      <td>0.118730</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.1, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.678071</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.841473</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.390362</td>\n",
       "      <td>0.431482</td>\n",
       "      <td>0.448803</td>\n",
       "      <td>0.445665</td>\n",
       "      <td>0.484933</td>\n",
       "      <td>0.447014</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>10.768218</td>\n",
       "      <td>0.861140</td>\n",
       "      <td>0.115372</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.10</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.1, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.367202</td>\n",
       "      <td>3.313513</td>\n",
       "      <td>0.106827</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.405932</td>\n",
       "      <td>2.845843</td>\n",
       "      <td>0.106640</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.885597</td>\n",
       "      <td>0.846327</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.873707</td>\n",
       "      <td>0.390362</td>\n",
       "      <td>0.876692</td>\n",
       "      <td>0.890387</td>\n",
       "      <td>0.905091</td>\n",
       "      <td>0.873111</td>\n",
       "      <td>0.788286</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>15.149598</td>\n",
       "      <td>2.439199</td>\n",
       "      <td>0.107430</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 1.0, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.904283</td>\n",
       "      <td>0.878443</td>\n",
       "      <td>0.895405</td>\n",
       "      <td>0.887811</td>\n",
       "      <td>0.867348</td>\n",
       "      <td>0.442294</td>\n",
       "      <td>0.877077</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.880188</td>\n",
       "      <td>0.891392</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>17.699769</td>\n",
       "      <td>3.105112</td>\n",
       "      <td>0.110928</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 1.0, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.905072</td>\n",
       "      <td>0.902444</td>\n",
       "      <td>0.900812</td>\n",
       "      <td>0.460809</td>\n",
       "      <td>0.868979</td>\n",
       "      <td>0.521318</td>\n",
       "      <td>0.885588</td>\n",
       "      <td>0.866955</td>\n",
       "      <td>0.882693</td>\n",
       "      <td>0.768566</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>16.339706</td>\n",
       "      <td>2.221698</td>\n",
       "      <td>0.110064</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.746891</td>\n",
       "      <td>2.282891</td>\n",
       "      <td>0.105228</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.893947</td>\n",
       "      <td>0.905019</td>\n",
       "      <td>0.887597</td>\n",
       "      <td>0.860752</td>\n",
       "      <td>0.902082</td>\n",
       "      <td>0.903774</td>\n",
       "      <td>0.406908</td>\n",
       "      <td>0.766147</td>\n",
       "      <td>0.895325</td>\n",
       "      <td>0.896796</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14.833671</td>\n",
       "      <td>2.237504</td>\n",
       "      <td>0.108267</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.5, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.893947</td>\n",
       "      <td>0.905019</td>\n",
       "      <td>0.887597</td>\n",
       "      <td>0.860752</td>\n",
       "      <td>0.902082</td>\n",
       "      <td>0.903774</td>\n",
       "      <td>0.406908</td>\n",
       "      <td>0.766147</td>\n",
       "      <td>0.895325</td>\n",
       "      <td>0.896796</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>17.947989</td>\n",
       "      <td>3.599527</td>\n",
       "      <td>0.111701</td>\n",
       "      <td>0.008946</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.5, 'fit_intercept':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.828636</td>\n",
       "      <td>3.263091</td>\n",
       "      <td>0.107538</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.904283</td>\n",
       "      <td>0.867247</td>\n",
       "      <td>0.895405</td>\n",
       "      <td>0.887811</td>\n",
       "      <td>0.867348</td>\n",
       "      <td>0.467372</td>\n",
       "      <td>0.877077</td>\n",
       "      <td>0.465537</td>\n",
       "      <td>0.880188</td>\n",
       "      <td>0.891392</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>16.407617</td>\n",
       "      <td>2.685889</td>\n",
       "      <td>0.108645</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.5, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.005044</td>\n",
       "      <td>3.217329</td>\n",
       "      <td>0.107194</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.097873</td>\n",
       "      <td>2.706510</td>\n",
       "      <td>0.106615</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.705693</td>\n",
       "      <td>3.178655</td>\n",
       "      <td>0.107101</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.903315</td>\n",
       "      <td>0.900577</td>\n",
       "      <td>0.895822</td>\n",
       "      <td>0.865751</td>\n",
       "      <td>0.884610</td>\n",
       "      <td>0.866291</td>\n",
       "      <td>0.875176</td>\n",
       "      <td>0.812621</td>\n",
       "      <td>0.894092</td>\n",
       "      <td>0.892417</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>16.513752</td>\n",
       "      <td>1.748615</td>\n",
       "      <td>0.107255</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.227806</td>\n",
       "      <td>3.178401</td>\n",
       "      <td>0.106714</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.411314</td>\n",
       "      <td>3.500342</td>\n",
       "      <td>0.107574</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.771472</td>\n",
       "      <td>3.406401</td>\n",
       "      <td>0.108640</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.920301</td>\n",
       "      <td>3.298324</td>\n",
       "      <td>0.108964</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.447674</td>\n",
       "      <td>3.316367</td>\n",
       "      <td>0.108160</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.436917</td>\n",
       "      <td>2.864318</td>\n",
       "      <td>0.109523</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.121337</td>\n",
       "      <td>3.221779</td>\n",
       "      <td>0.106003</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.177301</td>\n",
       "      <td>3.119436</td>\n",
       "      <td>0.109819</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.076295</td>\n",
       "      <td>3.140501</td>\n",
       "      <td>0.106163</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.216639</td>\n",
       "      <td>2.913608</td>\n",
       "      <td>0.105663</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.598308</td>\n",
       "      <td>3.371078</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.338748</td>\n",
       "      <td>3.138072</td>\n",
       "      <td>0.103855</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.377369</td>\n",
       "      <td>3.304694</td>\n",
       "      <td>0.105643</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.003459</td>\n",
       "      <td>3.467353</td>\n",
       "      <td>0.107186</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.833201</td>\n",
       "      <td>3.672577</td>\n",
       "      <td>0.109970</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>0.894378</td>\n",
       "      <td>0.904763</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.883003</td>\n",
       "      <td>0.855164</td>\n",
       "      <td>0.894224</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.573306</td>\n",
       "      <td>3.549306</td>\n",
       "      <td>0.107504</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.856159           0.844364           0.763602   \n",
       "1            0.901243           0.881711           0.838720   \n",
       "2            0.903315           0.900577           0.895822   \n",
       "3            0.829477           0.170521           0.170521   \n",
       "4            0.905102           0.904069           0.828610   \n",
       "5            0.629873           0.717537           0.822134   \n",
       "6            0.831527           0.871016           0.886255   \n",
       "7            0.902616           0.617659           0.814985   \n",
       "8            0.901922           0.902411           0.505266   \n",
       "9            0.707994           0.692316           0.591745   \n",
       "10           0.853347           0.862314           0.211975   \n",
       "11           0.889113           0.170521           0.170521   \n",
       "12           0.803998           0.904069           0.823931   \n",
       "13           0.803998           0.904069           0.828610   \n",
       "14           0.904979           0.828142           0.904133   \n",
       "15           0.744939           0.778259           0.520833   \n",
       "16           0.735819           0.334921           0.807248   \n",
       "17           0.343829           0.848469           0.506693   \n",
       "18           0.678071           0.725432           0.841473   \n",
       "19           0.678071           0.725432           0.841473   \n",
       "20           0.904867           0.862924           0.891995   \n",
       "21           0.904867           0.862924           0.891995   \n",
       "22           0.885597           0.846327           0.776642   \n",
       "23           0.904283           0.878443           0.895405   \n",
       "24           0.905072           0.902444           0.900812   \n",
       "25           0.904867           0.862924           0.891995   \n",
       "26           0.893947           0.905019           0.887597   \n",
       "27           0.893947           0.905019           0.887597   \n",
       "28           0.904867           0.862924           0.891995   \n",
       "29           0.904283           0.867247           0.895405   \n",
       "30           0.904867           0.862924           0.891995   \n",
       "31           0.904867           0.862924           0.891995   \n",
       "32           0.904867           0.862924           0.891995   \n",
       "33           0.903315           0.900577           0.895822   \n",
       "34           0.904867           0.862924           0.891995   \n",
       "35           0.904867           0.862924           0.891995   \n",
       "36           0.904867           0.862924           0.891995   \n",
       "37           0.904867           0.862924           0.891995   \n",
       "38           0.904867           0.862924           0.891995   \n",
       "39           0.904867           0.862924           0.891995   \n",
       "40           0.904867           0.862924           0.891995   \n",
       "41           0.904867           0.862924           0.891995   \n",
       "42           0.904867           0.862924           0.891995   \n",
       "43           0.904867           0.862924           0.891995   \n",
       "44           0.904867           0.862924           0.891995   \n",
       "45           0.904867           0.862924           0.891995   \n",
       "46           0.904867           0.862924           0.891995   \n",
       "47           0.904867           0.862924           0.891995   \n",
       "48           0.904867           0.862924           0.891995   \n",
       "49           0.904867           0.862924           0.891995   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0            0.687288           0.189770           0.234003   \n",
       "1            0.878828           0.454211           0.905782   \n",
       "2            0.865751           0.884610           0.866291   \n",
       "3            0.170520           0.170520           0.829276   \n",
       "4            0.881810           0.888196           0.892420   \n",
       "5            0.864994           0.874124           0.469429   \n",
       "6            0.181048           0.170523           0.189064   \n",
       "7            0.905607           0.886123           0.315340   \n",
       "8            0.904858           0.891052           0.753601   \n",
       "9            0.878828           0.411619           0.482024   \n",
       "10           0.882466           0.170520           0.331443   \n",
       "11           0.829480           0.829618           0.170520   \n",
       "12           0.893651           0.707838           0.902996   \n",
       "13           0.893651           0.707838           0.892420   \n",
       "14           0.704833           0.894301           0.704747   \n",
       "15           0.241191           0.285376           0.439782   \n",
       "16           0.898124           0.713673           0.703534   \n",
       "17           0.895635           0.886212           0.372121   \n",
       "18           0.851190           0.390362           0.431482   \n",
       "19           0.851190           0.390362           0.431482   \n",
       "20           0.894378           0.904763           0.905590   \n",
       "21           0.894378           0.904763           0.905590   \n",
       "22           0.873707           0.390362           0.876692   \n",
       "23           0.887811           0.867348           0.442294   \n",
       "24           0.460809           0.868979           0.521318   \n",
       "25           0.894378           0.904763           0.905590   \n",
       "26           0.860752           0.902082           0.903774   \n",
       "27           0.860752           0.902082           0.903774   \n",
       "28           0.894378           0.904763           0.905590   \n",
       "29           0.887811           0.867348           0.467372   \n",
       "30           0.894378           0.904763           0.905590   \n",
       "31           0.894378           0.904763           0.905590   \n",
       "32           0.894378           0.904763           0.905590   \n",
       "33           0.865751           0.884610           0.866291   \n",
       "34           0.894378           0.904763           0.905590   \n",
       "35           0.894378           0.904763           0.905590   \n",
       "36           0.894378           0.904763           0.905590   \n",
       "37           0.894378           0.904763           0.905590   \n",
       "38           0.894378           0.904763           0.905590   \n",
       "39           0.894378           0.904763           0.905590   \n",
       "40           0.894378           0.904763           0.905590   \n",
       "41           0.894378           0.904763           0.905590   \n",
       "42           0.894378           0.904763           0.905590   \n",
       "43           0.894378           0.904763           0.905590   \n",
       "44           0.894378           0.904763           0.905590   \n",
       "45           0.894378           0.904763           0.905590   \n",
       "46           0.894378           0.904763           0.905590   \n",
       "47           0.894378           0.904763           0.905590   \n",
       "48           0.894378           0.904763           0.905590   \n",
       "49           0.894378           0.904763           0.905590   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0            0.197109           0.212809           0.230172   \n",
       "1            0.455332           0.781880           0.886389   \n",
       "2            0.875176           0.812621           0.894092   \n",
       "3            0.170522           0.829135           0.829478   \n",
       "4            0.873100           0.693658           0.901210   \n",
       "5            0.508499           0.461719           0.516458   \n",
       "6            0.170549           0.830070           0.182337   \n",
       "7            0.872992           0.672438           0.896124   \n",
       "8            0.877707           0.349536           0.899536   \n",
       "9            0.525583           0.477180           0.889934   \n",
       "10           0.843843           0.838493           0.836147   \n",
       "11           0.883136           0.178352           0.829966   \n",
       "12           0.707103           0.693658           0.903248   \n",
       "13           0.873100           0.693658           0.903248   \n",
       "14           0.871060           0.721880           0.670290   \n",
       "15           0.439954           0.828969           0.411797   \n",
       "16           0.902329           0.693035           0.676169   \n",
       "17           0.871092           0.905056           0.902349   \n",
       "18           0.448803           0.445665           0.484933   \n",
       "19           0.448803           0.445665           0.484933   \n",
       "20           0.883003           0.855164           0.894224   \n",
       "21           0.883003           0.855164           0.894224   \n",
       "22           0.890387           0.905091           0.873111   \n",
       "23           0.877077           0.675556           0.880188   \n",
       "24           0.885588           0.866955           0.882693   \n",
       "25           0.883003           0.855164           0.894224   \n",
       "26           0.406908           0.766147           0.895325   \n",
       "27           0.406908           0.766147           0.895325   \n",
       "28           0.883003           0.855164           0.894224   \n",
       "29           0.877077           0.465537           0.880188   \n",
       "30           0.883003           0.855164           0.894224   \n",
       "31           0.883003           0.855164           0.894224   \n",
       "32           0.883003           0.855164           0.894224   \n",
       "33           0.875176           0.812621           0.894092   \n",
       "34           0.883003           0.855164           0.894224   \n",
       "35           0.883003           0.855164           0.894224   \n",
       "36           0.883003           0.855164           0.894224   \n",
       "37           0.883003           0.855164           0.894224   \n",
       "38           0.883003           0.855164           0.894224   \n",
       "39           0.883003           0.855164           0.894224   \n",
       "40           0.883003           0.855164           0.894224   \n",
       "41           0.883003           0.855164           0.894224   \n",
       "42           0.883003           0.855164           0.894224   \n",
       "43           0.883003           0.855164           0.894224   \n",
       "44           0.883003           0.855164           0.894224   \n",
       "45           0.883003           0.855164           0.894224   \n",
       "46           0.883003           0.855164           0.894224   \n",
       "47           0.883003           0.855164           0.894224   \n",
       "48           0.883003           0.855164           0.894224   \n",
       "49           0.883003           0.855164           0.894224   \n",
       "\n",
       "    split9_test_score  ...  rank_test_score  mean_fit_time  std_fit_time  \\\n",
       "0            0.683535  ...               47      11.959903      0.646242   \n",
       "1            0.782781  ...               34      15.527935      1.557045   \n",
       "2            0.892417  ...               28      14.198939      2.010234   \n",
       "3            0.829414  ...               50      16.012708      2.023319   \n",
       "4            0.844484  ...               24      15.772808      1.689184   \n",
       "5            0.540114  ...               42      12.006777      0.970923   \n",
       "6            0.837804  ...               49      15.774977      2.575142   \n",
       "7            0.894976  ...               36      16.973424      2.534266   \n",
       "8            0.903790  ...               33      13.041293      1.758001   \n",
       "9            0.527056  ...               41      12.577323      1.453766   \n",
       "10           0.842591  ...               43      15.059484      4.926035   \n",
       "11           0.874272  ...               48      17.162330      3.169464   \n",
       "12           0.844484  ...               30      13.886246      1.193946   \n",
       "13           0.844484  ...               25      15.073264      2.085024   \n",
       "14           0.839478  ...               38      15.643414      2.527428   \n",
       "15           0.781282  ...               46      14.578692      3.372017   \n",
       "16           0.845742  ...               40      13.466042      1.345153   \n",
       "17           0.904152  ...               39      12.400085      2.056384   \n",
       "18           0.447014  ...               44      12.408493      1.164491   \n",
       "19           0.447014  ...               44      10.768218      0.861140   \n",
       "20           0.845157  ...                1      18.367202      3.313513   \n",
       "21           0.845157  ...                1      15.405932      2.845843   \n",
       "22           0.788286  ...               37      15.149598      2.439199   \n",
       "23           0.891392  ...               31      17.699769      3.105112   \n",
       "24           0.768566  ...               32      16.339706      2.221698   \n",
       "25           0.845157  ...                1      15.746891      2.282891   \n",
       "26           0.896796  ...               26      14.833671      2.237504   \n",
       "27           0.896796  ...               26      17.947989      3.599527   \n",
       "28           0.845157  ...                1      17.828636      3.263091   \n",
       "29           0.891392  ...               35      16.407617      2.685889   \n",
       "30           0.845157  ...                1      18.005044      3.217329   \n",
       "31           0.845157  ...                1      18.097873      2.706510   \n",
       "32           0.845157  ...                1      18.705693      3.178655   \n",
       "33           0.892417  ...               28      16.513752      1.748615   \n",
       "34           0.845157  ...                1      18.227806      3.178401   \n",
       "35           0.845157  ...                1      18.411314      3.500342   \n",
       "36           0.845157  ...                1      18.771472      3.406401   \n",
       "37           0.845157  ...                1      17.920301      3.298324   \n",
       "38           0.845157  ...                1      18.447674      3.316367   \n",
       "39           0.845157  ...                1      18.436917      2.864318   \n",
       "40           0.845157  ...                1      18.121337      3.221779   \n",
       "41           0.845157  ...                1      18.177301      3.119436   \n",
       "42           0.845157  ...                1      18.076295      3.140501   \n",
       "43           0.845157  ...                1      18.216639      2.913608   \n",
       "44           0.845157  ...                1      18.598308      3.371078   \n",
       "45           0.845157  ...                1      18.338748      3.138072   \n",
       "46           0.845157  ...                1      18.377369      3.304694   \n",
       "47           0.845157  ...                1      19.003459      3.467353   \n",
       "48           0.845157  ...                1      18.833201      3.672577   \n",
       "49           0.845157  ...                1      18.573306      3.549306   \n",
       "\n",
       "    mean_score_time  std_score_time  param_alpha  param_eta0  \\\n",
       "0          0.120364        0.013754      0.00100        0.25   \n",
       "1          0.117550        0.013983      0.00001        0.75   \n",
       "2          0.111264        0.009045      0.00010        0.75   \n",
       "3          0.107845        0.008398      0.10000        0.50   \n",
       "4          0.106211        0.008074      0.00100        1.00   \n",
       "5          0.111023        0.006733      0.00010        0.10   \n",
       "6          0.107176        0.009172      0.01000        0.50   \n",
       "7          0.107158        0.007750      0.00010        1.00   \n",
       "8          0.107910        0.010050      0.00010        0.75   \n",
       "9          0.110008        0.010482      0.00001        0.25   \n",
       "10         0.105191        0.008319      0.00100        1.00   \n",
       "11         0.103798        0.007342      0.01000        0.75   \n",
       "12         0.109636        0.008425      0.00100        0.25   \n",
       "13         0.106207        0.005583      0.00100        0.50   \n",
       "14         0.107513        0.007705      0.00100        0.75   \n",
       "15         0.111036        0.010301      0.01000        0.75   \n",
       "16         0.113425        0.010742      0.00100        0.10   \n",
       "17         0.108575        0.007937      0.00010        0.25   \n",
       "18         0.118730        0.016599      0.00010        0.10   \n",
       "19         0.115372        0.010919      0.00010        0.10   \n",
       "20         0.106827        0.007384      0.00001        0.75   \n",
       "21         0.106640        0.006451      0.00001        0.75   \n",
       "22         0.107430        0.008664      0.00001        1.00   \n",
       "23         0.110928        0.012433      0.00010        1.00   \n",
       "24         0.110064        0.014137      0.00010        0.75   \n",
       "25         0.105228        0.006337      0.00001        0.75   \n",
       "26         0.108267        0.006591      0.00001        0.50   \n",
       "27         0.111701        0.008946      0.00001        0.50   \n",
       "28         0.107538        0.008279      0.00001        0.75   \n",
       "29         0.108645        0.009086      0.00010        0.50   \n",
       "30         0.107194        0.003882      0.00001        0.75   \n",
       "31         0.106615        0.006968      0.00001        0.75   \n",
       "32         0.107101        0.008232      0.00001        0.75   \n",
       "33         0.107255        0.003906      0.00010        0.75   \n",
       "34         0.106714        0.004982      0.00001        0.75   \n",
       "35         0.107574        0.006841      0.00001        0.75   \n",
       "36         0.108640        0.005140      0.00001        0.75   \n",
       "37         0.108964        0.007461      0.00001        0.75   \n",
       "38         0.108160        0.005094      0.00001        0.75   \n",
       "39         0.109523        0.006821      0.00001        0.75   \n",
       "40         0.106003        0.004894      0.00001        0.75   \n",
       "41         0.109819        0.007488      0.00001        0.75   \n",
       "42         0.106163        0.005956      0.00001        0.75   \n",
       "43         0.105663        0.006744      0.00001        0.75   \n",
       "44         0.108613        0.006340      0.00001        0.75   \n",
       "45         0.103855        0.004351      0.00001        0.75   \n",
       "46         0.105643        0.005431      0.00001        0.75   \n",
       "47         0.107186        0.008584      0.00001        0.75   \n",
       "48         0.109970        0.006564      0.00001        0.75   \n",
       "49         0.107504        0.009233      0.00001        0.75   \n",
       "\n",
       "    param_fit_intercept  param_penalty  \\\n",
       "0                 False     elasticnet   \n",
       "1                 False             l1   \n",
       "2                  True             l2   \n",
       "3                  True             l2   \n",
       "4                  True             l1   \n",
       "5                  True             l1   \n",
       "6                 False     elasticnet   \n",
       "7                 False     elasticnet   \n",
       "8                 False             l2   \n",
       "9                 False             l1   \n",
       "10                 True             l2   \n",
       "11                 True     elasticnet   \n",
       "12                 True             l1   \n",
       "13                 True             l1   \n",
       "14                 True             l1   \n",
       "15                 True             l1   \n",
       "16                 True             l1   \n",
       "17                 True             l2   \n",
       "18                 True     elasticnet   \n",
       "19                 True             l2   \n",
       "20                 True     elasticnet   \n",
       "21                 True             l2   \n",
       "22                 True     elasticnet   \n",
       "23                 True             l1   \n",
       "24                 True             l1   \n",
       "25                 True             l2   \n",
       "26                 True             l2   \n",
       "27                 True     elasticnet   \n",
       "28                 True     elasticnet   \n",
       "29                 True             l1   \n",
       "30                 True     elasticnet   \n",
       "31                 True     elasticnet   \n",
       "32                 True     elasticnet   \n",
       "33                 True     elasticnet   \n",
       "34                 True     elasticnet   \n",
       "35                 True     elasticnet   \n",
       "36                 True     elasticnet   \n",
       "37                 True     elasticnet   \n",
       "38                 True     elasticnet   \n",
       "39                 True     elasticnet   \n",
       "40                 True     elasticnet   \n",
       "41                 True     elasticnet   \n",
       "42                 True     elasticnet   \n",
       "43                 True     elasticnet   \n",
       "44                 True     elasticnet   \n",
       "45                 True     elasticnet   \n",
       "46                 True     elasticnet   \n",
       "47                 True     elasticnet   \n",
       "48                 True     elasticnet   \n",
       "49                 True     elasticnet   \n",
       "\n",
       "                                               params  \n",
       "0   {'alpha': 0.001, 'eta0': 0.25, 'fit_intercept'...  \n",
       "1   {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "2   {'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...  \n",
       "3   {'alpha': 0.1, 'eta0': 0.5, 'fit_intercept': T...  \n",
       "4   {'alpha': 0.001, 'eta0': 1.0, 'fit_intercept':...  \n",
       "5   {'alpha': 0.0001, 'eta0': 0.1, 'fit_intercept'...  \n",
       "6   {'alpha': 0.01, 'eta0': 0.5, 'fit_intercept': ...  \n",
       "7   {'alpha': 0.0001, 'eta0': 1.0, 'fit_intercept'...  \n",
       "8   {'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...  \n",
       "9   {'alpha': 1e-05, 'eta0': 0.25, 'fit_intercept'...  \n",
       "10  {'alpha': 0.001, 'eta0': 1.0, 'fit_intercept':...  \n",
       "11  {'alpha': 0.01, 'eta0': 0.75, 'fit_intercept':...  \n",
       "12  {'alpha': 0.001, 'eta0': 0.25, 'fit_intercept'...  \n",
       "13  {'alpha': 0.001, 'eta0': 0.5, 'fit_intercept':...  \n",
       "14  {'alpha': 0.001, 'eta0': 0.75, 'fit_intercept'...  \n",
       "15  {'alpha': 0.01, 'eta0': 0.75, 'fit_intercept':...  \n",
       "16  {'alpha': 0.001, 'eta0': 0.1, 'fit_intercept':...  \n",
       "17  {'alpha': 0.0001, 'eta0': 0.25, 'fit_intercept...  \n",
       "18  {'alpha': 0.0001, 'eta0': 0.1, 'fit_intercept'...  \n",
       "19  {'alpha': 0.0001, 'eta0': 0.1, 'fit_intercept'...  \n",
       "20  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "21  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "22  {'alpha': 1e-05, 'eta0': 1.0, 'fit_intercept':...  \n",
       "23  {'alpha': 0.0001, 'eta0': 1.0, 'fit_intercept'...  \n",
       "24  {'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...  \n",
       "25  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "26  {'alpha': 1e-05, 'eta0': 0.5, 'fit_intercept':...  \n",
       "27  {'alpha': 1e-05, 'eta0': 0.5, 'fit_intercept':...  \n",
       "28  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "29  {'alpha': 0.0001, 'eta0': 0.5, 'fit_intercept'...  \n",
       "30  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "31  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "32  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "33  {'alpha': 0.0001, 'eta0': 0.75, 'fit_intercept...  \n",
       "34  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "35  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "36  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "37  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "38  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "39  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "40  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "41  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "42  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "43  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "44  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "45  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "46  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "47  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "48  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "49  {'alpha': 1e-05, 'eta0': 0.75, 'fit_intercept'...  \n",
       "\n",
       "[50 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def optimize_perceptron():\n",
    "    model = sklearn.linear_model.Perceptron(\n",
    "        # penalty=None,\n",
    "        # alpha=0.0001,\n",
    "        # fit_intercept=True,\n",
    "        max_iter=10000,\n",
    "        tol=0.0001,\n",
    "        # shuffle=True,\n",
    "        # verbose=0,\n",
    "        # eta0=1.0,\n",
    "        n_jobs=5,\n",
    "        # random_state=1337,\n",
    "        # early_stopping=False,\n",
    "        # validation_fraction=0.1,\n",
    "        # n_iter_no_change=5,\n",
    "        class_weight=\"balanced\",\n",
    "        # warm_start=False\n",
    "    )\n",
    "\n",
    "    scaler = sklearn.preprocessing.Normalizer()\n",
    "\n",
    "    opt = skopt.BayesSearchCV(\n",
    "        model,\n",
    "        {\n",
    "            \"penalty\": skopt.space.Categorical([\"l2\", \"l1\", \"elasticnet\"]),\n",
    "            \"alpha\": skopt.space.Categorical([0.1, 0.01, 0.001, 0.0001, 0.00001]),\n",
    "            \"fit_intercept\": skopt.space.Categorical([True, False]),\n",
    "            \"eta0\": skopt.space.Categorical([0.1, 0.25, 0.5, 0.75, 1.0]),\n",
    "        },\n",
    "        n_iter=50,\n",
    "        cv=12,\n",
    "        n_jobs=10,\n",
    "    )\n",
    "\n",
    "    x_train = scaler.fit_transform(traindata[features])\n",
    "    y_train = traindata[label].values.ravel()\n",
    "\n",
    "    x_test = scaler.transform(testdata[features])\n",
    "    y_test = testdata[label].values.ravel()\n",
    "\n",
    "    start = time.time()\n",
    "    opt.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = opt.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    bac = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "    print(end - start, bac)\n",
    "    print(opt.best_params_)\n",
    "    display(pd.DataFrame(opt.cv_results_))\n",
    "\n",
    "\n",
    "optimize_perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.209331750869751\n",
      "0.8662147423478739\n"
     ]
    }
   ],
   "source": [
    "def train_nearcentroid():\n",
    "    model = sklearn.neighbors.NearestCentroid()\n",
    "    scaler = sklearn.preprocessing.Normalizer()\n",
    "\n",
    "    x_train = scaler.fit_transform(traindata[features])\n",
    "    y_train = traindata[label].values.ravel()\n",
    "\n",
    "    x_test = scaler.transform(testdata[features])\n",
    "    y_test = testdata[label].values.ravel()\n",
    "\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_true = y_test\n",
    "\n",
    "    bac = sklearn.metrics.balanced_accuracy_score(y_true, y_pred)\n",
    "    print(bac)\n",
    "    return model, scaler\n",
    "\n",
    "\n",
    "cent, cent_scaler = train_nearcentroid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
