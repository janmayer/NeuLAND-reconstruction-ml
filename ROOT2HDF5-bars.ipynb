{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert ROOT files Barfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the HDF5 file, it is good to know the number of events to store ahead of time. With ROOT, this requires a bit more code than it should, as you can't have multiple files opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_events(infiles):\n",
    "    # List Comprehension does not work with ROOT\n",
    "    num_events = 0\n",
    "    for _, filename in infiles:\n",
    "        tfile = ROOT.TFile.Open(filename)\n",
    "        ttree = tfile.Get(\"evt\")\n",
    "        num_events += ttree.GetEntries()\n",
    "    return num_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5(infiles, outfile, nDP):\n",
    "    num_bars = num_dp * 100\n",
    "    num_events = get_num_events(infiles)\n",
    "    chunksize = 1\n",
    "\n",
    "    print(f\"->     Writing to {outfile}\")\n",
    "    with h5py.File(outfile, \"w\") as h5file:\n",
    "        flatfeatures = h5file.create_dataset(\n",
    "            \"flatfeatures\",\n",
    "            shape=(num_events, num_bars * 2),\n",
    "            dtype=np.float32,\n",
    "            chunks=(chunksize, num_bars * 2),\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "        fbuff = np.zeros((num_bars * 2), np.float32)\n",
    "\n",
    "        consolidated = h5file.create_dataset(\n",
    "            \"consolidated\", shape=(num_events, 3), dtype=np.int16\n",
    "        )\n",
    "        cbuff = np.zeros((3), np.int16)\n",
    "\n",
    "        multiplicity = h5file.create_dataset(\"multiplicity\", (num_events, 3), np.int8)\n",
    "        mbuff = np.zeros((3), np.int8)\n",
    "\n",
    "        primhitsbars = h5file.create_dataset(\n",
    "            \"primhitsbars\",\n",
    "            shape=(num_events, num_bars),\n",
    "            dtype=np.int8,\n",
    "            chunks=(chunksize, num_bars),\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "        pbuff = np.zeros((num_bars), np.int8)\n",
    "\n",
    "        i = 0\n",
    "        for nIn, filename in infiles:\n",
    "            print(f\"Reading ROOT file {filename}\")\n",
    "            tfile = ROOT.TFile.Open(filename)\n",
    "            ttree = tfile.Get(\"evt\")\n",
    "            for event in ttree:\n",
    "                # Flatfeatures Features\n",
    "                fbuff.fill(0)\n",
    "                for hit in event.NeulandHits:\n",
    "                    bar = hit.GetPaddle() - 1\n",
    "                    fbuff[2 * bar + 0] = hit.GetE()\n",
    "                    fbuff[2 * bar + 1] = hit.GetT()\n",
    "                flatfeatures[i] = fbuff\n",
    "\n",
    "                # Consolidated Features\n",
    "                # nHits: Number of hits\n",
    "                cbuff[0] = event.NeulandHits.GetEntries()\n",
    "                # nClus: Number of clusters\n",
    "                cbuff[1] = event.NeulandClusters.GetEntries()\n",
    "                # Edep: Total deposited (detected) energy\n",
    "                cbuff[2] = round(sum([hit.GetE() for hit in event.NeulandHits]))\n",
    "                consolidated[i] = cbuff\n",
    "\n",
    "                # multiplicity\n",
    "                # nPN: Number of incoming primary neutrons\n",
    "                mbuff[0] = nIn\n",
    "                # nPP: Number of primary neutrons with an energy deposition in NeuLAND\n",
    "                mbuff[1] = event.NeulandPrimaryPoints.GetEntries()\n",
    "                # nPH: Number of hits that correspond to a energy deposition of a primary neutron\n",
    "                mbuff[2] = event.NeulandPrimaryHits.GetEntries()\n",
    "                multiplicity[i] = mbuff\n",
    "\n",
    "                # Primary Hits\n",
    "                pbuff.fill(0)\n",
    "                for phit in event.NeulandPrimaryHits:\n",
    "                    bar = phit.GetPaddle() - 1\n",
    "                    pbuff[bar] = 1\n",
    "                primhitsbars[i] = pbuff\n",
    "\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Don't try parallel execution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->     Writing to data/training_600AMeV_15dp.barfeature.h5\n",
      "Reading ROOT file simulation/training_600AMeV_15dp_1n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_15dp_2n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_15dp_3n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_15dp_4n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_15dp_5n.digi.root\n",
      "->     Writing to data/validation_600AMeV_15dp.barfeature.h5\n",
      "Reading ROOT file simulation/validation_600AMeV_15dp_1n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_15dp_2n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_15dp_3n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_15dp_4n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_15dp_5n.digi.root\n",
      "->     Writing to data/test_600AMeV_15dp.barfeature.h5\n",
      "Reading ROOT file simulation/test_600AMeV_15dp_1n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_15dp_2n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_15dp_3n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_15dp_4n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_15dp_5n.digi.root\n",
      "->     Writing to data/training_600AMeV_30dp.barfeature.h5\n",
      "Reading ROOT file simulation/training_600AMeV_30dp_1n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_30dp_2n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_30dp_3n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_30dp_4n.digi.root\n",
      "Reading ROOT file simulation/training_600AMeV_30dp_5n.digi.root\n",
      "->     Writing to data/validation_600AMeV_30dp.barfeature.h5\n",
      "Reading ROOT file simulation/validation_600AMeV_30dp_1n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_30dp_2n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_30dp_3n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_30dp_4n.digi.root\n",
      "Reading ROOT file simulation/validation_600AMeV_30dp_5n.digi.root\n",
      "->     Writing to data/test_600AMeV_30dp.barfeature.h5\n",
      "Reading ROOT file simulation/test_600AMeV_30dp_1n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_30dp_2n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_30dp_3n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_30dp_4n.digi.root\n",
      "Reading ROOT file simulation/test_600AMeV_30dp_5n.digi.root\n"
     ]
    }
   ],
   "source": [
    "incoming_neutrons = range(1, 6)\n",
    "beam_energy = 600\n",
    "\n",
    "\n",
    "def create_hdf5_wrap(num_dp):\n",
    "    infiles = [\n",
    "        (\n",
    "            neutrons,\n",
    "            f\"simulation/training_{beam_energy}AMeV_{num_dp}dp_{neutrons}n.digi.root\",\n",
    "        )\n",
    "        for neutrons in incoming_neutrons\n",
    "    ]\n",
    "    outfile = f\"data/{beam_energy}AMeV_{num_dp}dp.bars.h5\"\n",
    "    create_hdf5(infiles, outfile, num_dp)\n",
    "\n",
    "\n",
    "for num_dp in [15, 30]:\n",
    "    create_hdf5_wrap(num_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
