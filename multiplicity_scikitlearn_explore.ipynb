{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicity determination with Scikit-learn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import signal\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# from sklearn.utils.mocking import CheckingClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    RobustScaler,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    Normalizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('AdaBoostClassifier', AdaBoostClassifier(), 'fast'),\n",
    "    ('BaggingClassifier', BaggingClassifier(n_jobs=-1), 'fast'),\n",
    "    ('BernoulliNB', BernoulliNB(), 'fast'),\n",
    "    ('CalibratedClassifierCV', CalibratedClassifierCV(cv=5), 'slow'),\n",
    "    # dummy ('CheckingClassifier', CheckingClassifier(), 'fast'),\n",
    "    ('ComplementNB', ComplementNB(), 'fast'),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier(), 'fast'),\n",
    "    # dummy ('DummyClassifier', DummyClassifier(), 'fast'),\n",
    "    ('ExtraTreeClassifier', ExtraTreeClassifier(), 'fast'),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=100, n_jobs=-1), 'fast'),\n",
    "    ('GaussianNB', GaussianNB(), 'fast'),\n",
    "    # crashes ('GaussianProcessClassifier', GaussianProcessClassifier(), 'slow'),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier(), 'slow'),\n",
    "    ('HistGradientBoostingClassifier', HistGradientBoostingClassifier(), 'slow'),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier(n_jobs=-1), 'fast'),\n",
    "    # ('LabelPropagation', LabelPropagation(), 'slow'),  # requires too much memory to train with larger datasets\n",
    "    # ('LabelSpreading', LabelSpreading(), 'slow'),  # bit slow\n",
    "    ('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis(), 'fast'),\n",
    "    ('LogisticRegression', LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=20000), 'slow'),  # slow with unscaled data\n",
    "    ('LogisticRegressionCV', LogisticRegressionCV(cv=5, solver='lbfgs', multi_class='auto', max_iter=20000), 'slow'),  # slow\n",
    "    ('MLPClassifier', MLPClassifier(), 'slow'),\n",
    "    ('MultinomialNB', MultinomialNB(), 'fast'),\n",
    "    ('NearestCentroid', NearestCentroid(), 'fast'),\n",
    "    # nu infeasible ('NuSVC', NuSVC(), 'fast'),\n",
    "    ('PassiveAggressiveClassifier', PassiveAggressiveClassifier(max_iter=1000, tol=1e-3, n_jobs=-1), 'fast'),\n",
    "    ('Perceptron', Perceptron(n_jobs=-1), 'fast'),\n",
    "    ('QuadraticDiscriminantAnalysis', QuadraticDiscriminantAnalysis(), 'fast'),\n",
    "    ('RadiusNeighborsClassifier', RadiusNeighborsClassifier(radius=2, outlier_label=0, n_jobs=-1), 'fast'),\n",
    "    ('RandomForestClassifier', RandomForestClassifier(n_estimators=100, n_jobs=-1), 'fast'),\n",
    "    ('RidgeClassifier', RidgeClassifier(), 'fast'),\n",
    "    ('RidgeClassifierCV', RidgeClassifierCV(), 'fast'),\n",
    "    ('SGDClassifier', SGDClassifier(max_iter=1000, tol=1e-3, n_jobs=-1), 'fast'),\n",
    "    ('LinearSVC', LinearSVC(max_iter=20000), 'slow'),  # slow with unscaled data\n",
    "    ('SVC', SVC(gamma='scale'), 'slow'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [\n",
    "    # ('Unscaled data', ),\n",
    "    ('standard scaling', StandardScaler()),\n",
    "    ('min-max scaling', MinMaxScaler()),\n",
    "    ('max-abs scaling', MaxAbsScaler()),\n",
    "    ('robust scaling', RobustScaler(quantile_range=(25, 75))),\n",
    "    ('power transformation (Yeo-Johnson)', PowerTransformer(method='yeo-johnson')),\n",
    "    # ('power transformation (Box-Cox)', PowerTransformer(method='box-cox')), # 'strictly zero' meh.\n",
    "    ('quantile transformation (gaussian pdf)', QuantileTransformer(output_distribution='normal')),\n",
    "    ('quantile transformation (uniform pdf)', QuantileTransformer(output_distribution='uniform')),\n",
    "    ('sample-wise L2 normalizing', Normalizer()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dp = 30\n",
    "\n",
    "traindata = pd.read_pickle(f\"data/training_600AMeV_{num_dp}dp.pkl\").sample(frac=0.1)\n",
    "testdata = pd.read_pickle(f\"data/test_600AMeV_{num_dp}dp.pkl\")\n",
    "\n",
    "trainscaled = [\n",
    "    (\n",
    "        \"Unscaled data\",\n",
    "        traindata[[\"nHits\", \"nClus\", \"Edep\"]],\n",
    "        testdata[[\"nHits\", \"nClus\", \"Edep\"]],\n",
    "    )\n",
    "] + [\n",
    "    (\n",
    "        sname,\n",
    "        scaler.fit_transform(traindata[[\"nHits\", \"nClus\", \"Edep\"]]),\n",
    "        scaler.transform(testdata[[\"nHits\", \"nClus\", \"Edep\"]]),\n",
    "    )\n",
    "    for sname, scaler in scalers\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoostClassifier', 'Unscaled data', 0.539658957878153, '1.7389185428619385')\n",
      "('AdaBoostClassifier', 'standard scaling', 0.539658957878153, '1.7516717910766602')\n",
      "('AdaBoostClassifier', 'min-max scaling', 0.539658957878153, '1.787578821182251')\n",
      "('AdaBoostClassifier', 'max-abs scaling', 0.539658957878153, '1.883124589920044')\n",
      "('AdaBoostClassifier', 'robust scaling', 0.539658957878153, '1.8192639350891113')\n",
      "('AdaBoostClassifier', 'power transformation (Yeo-Johnson)', 0.539658957878153, '1.7480335235595703')\n",
      "('AdaBoostClassifier', 'quantile transformation (gaussian pdf)', 0.539658957878153, '1.7963471412658691')\n",
      "('AdaBoostClassifier', 'quantile transformation (uniform pdf)', 0.539658957878153, '1.8270554542541504')\n",
      "('AdaBoostClassifier', 'sample-wise L2 normalizing', 0.3630045864033875, '2.4161384105682373')\n",
      "('BaggingClassifier', 'Unscaled data', 0.7274498120211931, '0.16216015815734863')\n",
      "('BaggingClassifier', 'standard scaling', 0.7280732486022977, '0.19832205772399902')\n",
      "('BaggingClassifier', 'min-max scaling', 0.7277462201409172, '0.2111492156982422')\n",
      "('BaggingClassifier', 'max-abs scaling', 0.7281032642650244, '0.31004834175109863')\n",
      "('BaggingClassifier', 'robust scaling', 0.7276414044664095, '0.3126194477081299')\n",
      "('BaggingClassifier', 'power transformation (Yeo-Johnson)', 0.7280814581919278, '0.41785693168640137')\n",
      "('BaggingClassifier', 'quantile transformation (gaussian pdf)', 0.7292525077420153, '0.42943382263183594')\n",
      "('BaggingClassifier', 'quantile transformation (uniform pdf)', 0.7270781194539547, '0.3587496280670166')\n",
      "('BaggingClassifier', 'sample-wise L2 normalizing', 0.4183790914815222, '0.8164775371551514')\n",
      "('BernoulliNB', 'Unscaled data', 0.3333594129478767, '0.015007734298706055')\n",
      "('BernoulliNB', 'standard scaling', 0.40920163220741995, '0.019490957260131836')\n",
      "('BernoulliNB', 'min-max scaling', 0.3333594129478767, '0.012591361999511719')\n",
      "('BernoulliNB', 'max-abs scaling', 0.3333594129478767, '0.013719320297241211')\n",
      "('BernoulliNB', 'robust scaling', 0.41391938831264824, '0.014999866485595703')\n",
      "('BernoulliNB', 'power transformation (Yeo-Johnson)', 0.4197810036838005, '0.015215873718261719')\n",
      "('BernoulliNB', 'quantile transformation (gaussian pdf)', 0.41391938831264824, '0.016432523727416992')\n",
      "('BernoulliNB', 'quantile transformation (uniform pdf)', 0.3333594129478767, '0.017657041549682617')\n",
      "('BernoulliNB', 'sample-wise L2 normalizing', 0.3333594129478767, '0.014181852340698242')\n",
      "('CalibratedClassifierCV', 'Unscaled data', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'standard scaling', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'min-max scaling', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'max-abs scaling', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'robust scaling', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'power transformation (Yeo-Johnson)', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'quantile transformation (gaussian pdf)', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'quantile transformation (uniform pdf)', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('CalibratedClassifierCV', 'sample-wise L2 normalizing', nan, ValueError('Requesting 5-fold cross-validation but provided less than 5 examples for at least one class.'))\n",
      "('ComplementNB', 'Unscaled data', 0.34075203211029687, '0.01304006576538086')\n",
      "('ComplementNB', 'standard scaling', nan, ValueError('Negative values in data passed to ComplementNB (input X)'))\n",
      "('ComplementNB', 'min-max scaling', 0.34001885958955497, '0.011427879333496094')\n",
      "('ComplementNB', 'max-abs scaling', 0.34001885958955497, '0.016436100006103516')\n",
      "('ComplementNB', 'robust scaling', nan, ValueError('Negative values in data passed to ComplementNB (input X)'))\n",
      "('ComplementNB', 'power transformation (Yeo-Johnson)', nan, ValueError('Negative values in data passed to ComplementNB (input X)'))\n",
      "('ComplementNB', 'quantile transformation (gaussian pdf)', nan, ValueError('Negative values in data passed to ComplementNB (input X)'))\n",
      "('ComplementNB', 'quantile transformation (uniform pdf)', 0.3484635049230265, '0.012374639511108398')\n",
      "('ComplementNB', 'sample-wise L2 normalizing', 0.3575234894867618, '0.012300252914428711')\n",
      "('DecisionTreeClassifier', 'Unscaled data', 0.6912776777447939, '0.12480497360229492')\n",
      "('DecisionTreeClassifier', 'standard scaling', 0.6913222776058144, '0.15144586563110352')\n",
      "('DecisionTreeClassifier', 'min-max scaling', 0.6910842009495078, '0.15448570251464844')\n",
      "('DecisionTreeClassifier', 'max-abs scaling', 0.6915058487671741, '0.14243125915527344')\n",
      "('DecisionTreeClassifier', 'robust scaling', 0.6912271184697985, '0.13661956787109375')\n",
      "('DecisionTreeClassifier', 'power transformation (Yeo-Johnson)', 0.6914179078469602, '0.13861656188964844')\n",
      "('DecisionTreeClassifier', 'quantile transformation (gaussian pdf)', 0.6912488693909626, '0.1400012969970703')\n",
      "('DecisionTreeClassifier', 'quantile transformation (uniform pdf)', 0.6909452843686431, '0.14374661445617676')\n",
      "('DecisionTreeClassifier', 'sample-wise L2 normalizing', 0.41364859562805306, '0.49253153800964355')\n",
      "('ExtraTreeClassifier', 'Unscaled data', 0.6938914885740605, '0.03882765769958496')\n",
      "('ExtraTreeClassifier', 'standard scaling', 0.6947036152513856, '0.03687858581542969')\n",
      "('ExtraTreeClassifier', 'min-max scaling', 0.6963303712888466, '0.038616180419921875')\n",
      "('ExtraTreeClassifier', 'max-abs scaling', 0.6954136520523053, '0.03899431228637695')\n",
      "('ExtraTreeClassifier', 'robust scaling', 0.6929617296944596, '0.037560224533081055')\n",
      "('ExtraTreeClassifier', 'power transformation (Yeo-Johnson)', 0.6947243488749241, '0.04127073287963867')\n",
      "('ExtraTreeClassifier', 'quantile transformation (gaussian pdf)', 0.6942848778317673, '0.041945457458496094')\n",
      "('ExtraTreeClassifier', 'quantile transformation (uniform pdf)', 0.6954338917710926, '0.0651082992553711')\n",
      "('ExtraTreeClassifier', 'sample-wise L2 normalizing', 0.41364661076489223, '0.0708920955657959')\n",
      "('ExtraTreesClassifier', 'Unscaled data', 0.72047432828676, '3.955930233001709')\n",
      "('ExtraTreesClassifier', 'standard scaling', 0.7206455248022826, '1.317122220993042')\n",
      "('ExtraTreesClassifier', 'min-max scaling', 0.7210157210499918, '1.1363990306854248')\n",
      "('ExtraTreesClassifier', 'max-abs scaling', 0.7200025662165149, '2.1530044078826904')\n",
      "('ExtraTreesClassifier', 'robust scaling', 0.7193222367601972, '1.7829508781433105')\n",
      "('ExtraTreesClassifier', 'power transformation (Yeo-Johnson)', 0.7199963229140547, '5.1170666217803955')\n",
      "('ExtraTreesClassifier', 'quantile transformation (gaussian pdf)', 0.7197853182144288, '3.872720718383789')\n",
      "('ExtraTreesClassifier', 'quantile transformation (uniform pdf)', 0.7195452034911876, '3.282728910446167')\n",
      "('ExtraTreesClassifier', 'sample-wise L2 normalizing', 0.4214310681144036, '3.4751384258270264')\n",
      "('GaussianNB', 'Unscaled data', 0.7373636761064727, '0.013548851013183594')\n",
      "('GaussianNB', 'standard scaling', 0.7373636761064727, '0.012933969497680664')\n",
      "('GaussianNB', 'min-max scaling', 0.7373636761064727, '0.01371145248413086')\n",
      "('GaussianNB', 'max-abs scaling', 0.7373636761064727, '0.014264345169067383')\n",
      "('GaussianNB', 'robust scaling', 0.7373636761064727, '0.015915393829345703')\n",
      "('GaussianNB', 'power transformation (Yeo-Johnson)', 0.7386121132264288, '0.024316787719726562')\n",
      "('GaussianNB', 'quantile transformation (gaussian pdf)', 0.7379930373236037, '0.016691923141479492')\n",
      "('GaussianNB', 'quantile transformation (uniform pdf)', 0.7309906139274812, '0.016622304916381836')\n",
      "('GaussianNB', 'sample-wise L2 normalizing', 0.37953176319034254, '0.011880159378051758')\n",
      "('GradientBoostingClassifier', 'Unscaled data', 0.7402939143068065, '1.1182448863983154')\n",
      "('GradientBoostingClassifier', 'standard scaling', 0.7402527247122962, '1.1097116470336914')\n",
      "('GradientBoostingClassifier', 'min-max scaling', 0.7401901500237281, '1.1286485195159912')\n",
      "('GradientBoostingClassifier', 'max-abs scaling', 0.7402758450883518, '1.0929744243621826')\n",
      "('GradientBoostingClassifier', 'robust scaling', 0.7403022659107483, '1.0991530418395996')\n",
      "('GradientBoostingClassifier', 'power transformation (Yeo-Johnson)', 0.7404190487204959, '1.1064496040344238')\n",
      "('GradientBoostingClassifier', 'quantile transformation (gaussian pdf)', 0.7404130797123871, '1.084416151046753')\n",
      "('GradientBoostingClassifier', 'quantile transformation (uniform pdf)', 0.7396227804461099, '1.1387684345245361')\n",
      "('GradientBoostingClassifier', 'sample-wise L2 normalizing', 0.40434750639221306, '1.2374210357666016')\n",
      "('HistGradientBoostingClassifier', 'Unscaled data', 0.5597927108658575, '3.977625846862793')\n",
      "('HistGradientBoostingClassifier', 'standard scaling', 0.5597814026607383, '3.9059255123138428')\n",
      "('HistGradientBoostingClassifier', 'min-max scaling', 0.5597585019071605, '4.0203869342803955')\n",
      "('HistGradientBoostingClassifier', 'max-abs scaling', 0.5597860789395567, '3.2517478466033936')\n",
      "('HistGradientBoostingClassifier', 'robust scaling', 0.5597878173106369, '3.013716459274292')\n",
      "('HistGradientBoostingClassifier', 'power transformation (Yeo-Johnson)', 0.5596498717249387, '3.82305645942688')\n",
      "('HistGradientBoostingClassifier', 'quantile transformation (gaussian pdf)', 0.55969462500011, '4.006009340286255')\n",
      "('HistGradientBoostingClassifier', 'quantile transformation (uniform pdf)', 0.5597373163524599, '3.804293155670166')\n",
      "('HistGradientBoostingClassifier', 'sample-wise L2 normalizing', 0.39230443089067824, '4.079325914382935')\n",
      "('KNeighborsClassifier', 'Unscaled data', 0.7410560551748357, '0.04267764091491699')\n",
      "('KNeighborsClassifier', 'standard scaling', 0.7450194984839733, '0.04236721992492676')\n",
      "('KNeighborsClassifier', 'min-max scaling', 0.745126690699396, '0.041500091552734375')\n",
      "('KNeighborsClassifier', 'max-abs scaling', 0.7451635656831468, '0.046294212341308594')\n",
      "('KNeighborsClassifier', 'robust scaling', 0.7450951018789472, '0.05951237678527832')\n",
      "('KNeighborsClassifier', 'power transformation (Yeo-Johnson)', 0.7448440816896321, '0.06598687171936035')\n",
      "('KNeighborsClassifier', 'quantile transformation (gaussian pdf)', 0.7449830712434878, '0.21617889404296875')\n",
      "('KNeighborsClassifier', 'quantile transformation (uniform pdf)', 0.7448225407282832, '0.1620006561279297')\n",
      "('KNeighborsClassifier', 'sample-wise L2 normalizing', 0.4063080509405763, '0.17930006980895996')\n",
      "('LinearDiscriminantAnalysis', 'Unscaled data', 0.6039495272990271, '0.033643484115600586')\n",
      "('LinearDiscriminantAnalysis', 'standard scaling', 0.6039495272990271, '0.03596019744873047')\n",
      "('LinearDiscriminantAnalysis', 'min-max scaling', 0.6039495272990271, '0.036225080490112305')\n",
      "('LinearDiscriminantAnalysis', 'max-abs scaling', 0.6039495272990271, '0.0470578670501709')\n",
      "('LinearDiscriminantAnalysis', 'robust scaling', 0.6039495272990271, '0.03762698173522949')\n",
      "('LinearDiscriminantAnalysis', 'power transformation (Yeo-Johnson)', 0.7635048728324749, '0.05884885787963867')\n",
      "('LinearDiscriminantAnalysis', 'quantile transformation (gaussian pdf)', 0.7655875710292254, '0.0650472640991211')\n",
      "('LinearDiscriminantAnalysis', 'quantile transformation (uniform pdf)', 0.5949897811954598, '0.04486823081970215')\n",
      "('LinearDiscriminantAnalysis', 'sample-wise L2 normalizing', 0.34712790544099015, '0.03838968276977539')\n",
      "('LogisticRegression', 'Unscaled data', 0.7638042476354506, '7.524081707000732')\n",
      "('LogisticRegression', 'standard scaling', 0.5922643977192404, '0.07120800018310547')\n",
      "('LogisticRegression', 'min-max scaling', 0.5698189956624452, '0.09000134468078613')\n",
      "('LogisticRegression', 'max-abs scaling', 0.5698189956624452, '0.06780052185058594')\n",
      "('LogisticRegression', 'robust scaling', 0.5882592150296825, '0.09708213806152344')\n",
      "('LogisticRegression', 'power transformation (Yeo-Johnson)', 0.5892847755644969, '0.10170388221740723')\n",
      "('LogisticRegression', 'quantile transformation (gaussian pdf)', 0.7573275787819056, '0.07974863052368164')\n",
      "('LogisticRegression', 'quantile transformation (uniform pdf)', 0.57444846274459, '0.09093451499938965')\n",
      "('LogisticRegression', 'sample-wise L2 normalizing', 0.1788255409563468, '0.05816388130187988')\n",
      "('LogisticRegressionCV', 'Unscaled data', 0.7639257364572596, '56.57364535331726')\n",
      "('LogisticRegressionCV', 'standard scaling', 0.5974883690585884, '6.480245351791382')\n",
      "('LogisticRegressionCV', 'min-max scaling', 0.5970658830017159, '7.808846950531006')\n",
      "('LogisticRegressionCV', 'max-abs scaling', 0.5973544116987556, '7.896906614303589')\n",
      "('LogisticRegressionCV', 'robust scaling', 0.5972563520783195, '5.229116916656494')\n",
      "('LogisticRegressionCV', 'power transformation (Yeo-Johnson)', 0.7600602672689246, '5.319195747375488')\n",
      "('LogisticRegressionCV', 'quantile transformation (gaussian pdf)', 0.7608471090298764, '2.9840316772460938')\n",
      "('LogisticRegressionCV', 'quantile transformation (uniform pdf)', 0.5921231657681033, '6.097206354141235')\n",
      "('LogisticRegressionCV', 'sample-wise L2 normalizing', 0.35958355814170645, '5.712465524673462')\n",
      "('MLPClassifier', 'Unscaled data', 0.4220638668733214, '0.25079846382141113')\n",
      "('MLPClassifier', 'standard scaling', 0.5968842916697362, '1.0254929065704346')\n",
      "('MLPClassifier', 'min-max scaling', 0.5887059580021954, '0.9762406349182129')\n",
      "('MLPClassifier', 'max-abs scaling', 0.5874003519464819, '1.050572156906128')\n",
      "('MLPClassifier', 'robust scaling', 0.5948958067815154, '0.9815378189086914')\n",
      "('MLPClassifier', 'power transformation (Yeo-Johnson)', 0.5960577662474674, '1.103203535079956')\n",
      "('MLPClassifier', 'quantile transformation (gaussian pdf)', 0.7642805921746237, '1.060718297958374')\n",
      "('MLPClassifier', 'quantile transformation (uniform pdf)', 0.583940712342142, '1.0015764236450195')\n",
      "('MLPClassifier', 'sample-wise L2 normalizing', 0.36661959938502414, '1.0472564697265625')\n",
      "('MultinomialNB', 'Unscaled data', 0.17744626838691724, '0.012794971466064453')\n",
      "('MultinomialNB', 'standard scaling', nan, ValueError('Negative values in data passed to MultinomialNB (input X)'))\n",
      "('MultinomialNB', 'min-max scaling', 0.16666666666666666, '0.013105392456054688')\n",
      "('MultinomialNB', 'max-abs scaling', 0.16666666666666666, '0.012727737426757812')\n",
      "('MultinomialNB', 'robust scaling', nan, ValueError('Negative values in data passed to MultinomialNB (input X)'))\n",
      "('MultinomialNB', 'power transformation (Yeo-Johnson)', nan, ValueError('Negative values in data passed to MultinomialNB (input X)'))\n",
      "('MultinomialNB', 'quantile transformation (gaussian pdf)', nan, ValueError('Negative values in data passed to MultinomialNB (input X)'))\n",
      "('MultinomialNB', 'quantile transformation (uniform pdf)', 0.16629419449319718, '0.012090682983398438')\n",
      "('MultinomialNB', 'sample-wise L2 normalizing', 0.1815673955381331, '0.012398481369018555')\n",
      "('NearestCentroid', 'Unscaled data', 0.6341061308591956, '0.008219003677368164')\n",
      "('NearestCentroid', 'standard scaling', 0.7298805705722043, '0.008101940155029297')\n",
      "('NearestCentroid', 'min-max scaling', 0.725705899296218, '0.008443355560302734')\n",
      "('NearestCentroid', 'max-abs scaling', 0.725705899296218, '0.008669137954711914')\n",
      "('NearestCentroid', 'robust scaling', 0.7302392538803332, '0.007653236389160156')\n",
      "('NearestCentroid', 'power transformation (Yeo-Johnson)', 0.7337247491406461, '0.009405374526977539')\n",
      "('NearestCentroid', 'quantile transformation (gaussian pdf)', 0.7440915168193293, '0.012441635131835938')\n",
      "('NearestCentroid', 'quantile transformation (uniform pdf)', 0.7138812205609203, '0.012740373611450195')\n",
      "('NearestCentroid', 'sample-wise L2 normalizing', 0.35986165881346555, '0.011930465698242188')\n",
      "('PassiveAggressiveClassifier', 'Unscaled data', 0.19358561003683264, '0.14493131637573242')\n",
      "('PassiveAggressiveClassifier', 'standard scaling', 0.4125757372956696, '0.09103584289550781')\n",
      "('PassiveAggressiveClassifier', 'min-max scaling', 0.44714490994656614, '0.0691685676574707')\n",
      "('PassiveAggressiveClassifier', 'max-abs scaling', 0.37434645288825674, '0.06967353820800781')\n",
      "('PassiveAggressiveClassifier', 'robust scaling', 0.4938250598908123, '0.1452805995941162')\n",
      "('PassiveAggressiveClassifier', 'power transformation (Yeo-Johnson)', 0.34526087846091125, '0.15179991722106934')\n",
      "('PassiveAggressiveClassifier', 'quantile transformation (gaussian pdf)', 0.38761078053907666, '0.19369888305664062')\n",
      "('PassiveAggressiveClassifier', 'quantile transformation (uniform pdf)', 0.40332471405051157, '0.1186974048614502')\n",
      "('PassiveAggressiveClassifier', 'sample-wise L2 normalizing', 0.17188346492950424, '0.10352253913879395')\n",
      "('Perceptron', 'Unscaled data', 0.23764265588456102, '0.37125349044799805')\n",
      "('Perceptron', 'standard scaling', 0.46462282523715204, '0.13584518432617188')\n",
      "('Perceptron', 'min-max scaling', 0.288509897786615, '0.06118655204772949')\n",
      "('Perceptron', 'max-abs scaling', 0.288509897786615, '0.11001372337341309')\n",
      "('Perceptron', 'robust scaling', 0.40166220813489045, '0.08046936988830566')\n",
      "('Perceptron', 'power transformation (Yeo-Johnson)', 0.46426991842526166, '0.11721920967102051')\n",
      "('Perceptron', 'quantile transformation (gaussian pdf)', 0.1895221032579825, '0.10284662246704102')\n",
      "('Perceptron', 'quantile transformation (uniform pdf)', 0.33357655561149463, '0.09042620658874512')\n",
      "('Perceptron', 'sample-wise L2 normalizing', 0.33989590316423124, '0.13420796394348145')\n",
      "('QuadraticDiscriminantAnalysis', 'Unscaled data', 0.16666666666666666, '0.012403726577758789')\n",
      "('QuadraticDiscriminantAnalysis', 'standard scaling', 0.7663070684901746, '0.013704061508178711')\n",
      "('QuadraticDiscriminantAnalysis', 'min-max scaling', 0.16666666666666666, '0.014167547225952148')\n",
      "('QuadraticDiscriminantAnalysis', 'max-abs scaling', 0.16666666666666666, '0.014954805374145508')\n",
      "('QuadraticDiscriminantAnalysis', 'robust scaling', 0.599640401823508, '0.012974262237548828')\n",
      "('QuadraticDiscriminantAnalysis', 'power transformation (Yeo-Johnson)', 0.5997838817924961, '0.018697738647460938')\n",
      "('QuadraticDiscriminantAnalysis', 'quantile transformation (gaussian pdf)', 0.761374611034732, '0.020014047622680664')\n",
      "('QuadraticDiscriminantAnalysis', 'quantile transformation (uniform pdf)', 0.16666666666666666, '0.015609979629516602')\n",
      "('QuadraticDiscriminantAnalysis', 'sample-wise L2 normalizing', 0.16666666666666666, '0.024367809295654297')\n",
      "('RadiusNeighborsClassifier', 'Unscaled data', nan, TypeError('The dtype of outlier_label 0 is inconsistent with classes [0 1 2 3 4 5] in y.'))\n",
      "('RadiusNeighborsClassifier', 'standard scaling', nan, 'Skipped')\n",
      "('RadiusNeighborsClassifier', 'min-max scaling', nan, 'Skipped')\n",
      "('RadiusNeighborsClassifier', 'max-abs scaling', nan, 'Skipped')\n",
      "('RadiusNeighborsClassifier', 'robust scaling', nan, 'Skipped')\n",
      "('RadiusNeighborsClassifier', 'power transformation (Yeo-Johnson)', nan, 'Skipped')\n",
      "('RadiusNeighborsClassifier', 'quantile transformation (gaussian pdf)', nan, 'Skipped')\n",
      "('RadiusNeighborsClassifier', 'quantile transformation (uniform pdf)', nan, 'Skipped')\n",
      "('RadiusNeighborsClassifier', 'sample-wise L2 normalizing', nan, 'Skipped')\n",
      "('RandomForestClassifier', 'Unscaled data', 0.7298976394973474, '2.0280444622039795')\n",
      "('RandomForestClassifier', 'standard scaling', 0.729303754955401, '2.243910074234009')\n",
      "('RandomForestClassifier', 'min-max scaling', 0.7297679953062411, '2.191260814666748')\n",
      "('RandomForestClassifier', 'max-abs scaling', 0.7297325283356105, '2.2755205631256104')\n",
      "('RandomForestClassifier', 'robust scaling', 0.7302037779830067, '4.298394203186035')\n",
      "('RandomForestClassifier', 'power transformation (Yeo-Johnson)', 0.7304643103734257, '2.197458505630493')\n",
      "('RandomForestClassifier', 'quantile transformation (gaussian pdf)', 0.7302574417021438, '2.249171495437622')\n",
      "('RandomForestClassifier', 'quantile transformation (uniform pdf)', 0.7297078901365915, '2.7409780025482178')\n",
      "('RandomForestClassifier', 'sample-wise L2 normalizing', 0.42250152032763966, '5.971040964126587')\n",
      "('RidgeClassifier', 'Unscaled data', 0.3512114888202809, '0.025573253631591797')\n",
      "('RidgeClassifier', 'standard scaling', 0.3512049766256545, '0.02594447135925293')\n",
      "('RidgeClassifier', 'min-max scaling', 0.35111476889305265, '0.033635854721069336')\n",
      "('RidgeClassifier', 'max-abs scaling', 0.35111476889305265, '0.026113271713256836')\n",
      "('RidgeClassifier', 'robust scaling', 0.3511952088622124, '0.025546550750732422')\n",
      "('RidgeClassifier', 'power transformation (Yeo-Johnson)', 0.35374314874407475, '0.026516437530517578')\n",
      "('RidgeClassifier', 'quantile transformation (gaussian pdf)', 0.3557008372366057, '0.03596949577331543')\n",
      "('RidgeClassifier', 'quantile transformation (uniform pdf)', 0.35653229583214907, '0.03386425971984863')\n",
      "('RidgeClassifier', 'sample-wise L2 normalizing', 0.33883730117766847, '0.029263019561767578')\n",
      "('RidgeClassifierCV', 'Unscaled data', 0.3512114888202809, '0.06012701988220215')\n",
      "('RidgeClassifierCV', 'standard scaling', 0.3511497455627506, '0.05890321731567383')\n",
      "('RidgeClassifierCV', 'min-max scaling', 0.3511935749233413, '0.05793476104736328')\n",
      "('RidgeClassifierCV', 'max-abs scaling', 0.3511935749233413, '0.08261823654174805')\n",
      "('RidgeClassifierCV', 'robust scaling', 0.3511952088622124, '0.07050037384033203')\n",
      "('RidgeClassifierCV', 'power transformation (Yeo-Johnson)', 0.3537096090931091, '0.06376767158508301')\n",
      "('RidgeClassifierCV', 'quantile transformation (gaussian pdf)', 0.3556729864222376, '0.06793642044067383')\n",
      "('RidgeClassifierCV', 'quantile transformation (uniform pdf)', 0.35653229583214907, '0.07964682579040527')\n",
      "('RidgeClassifierCV', 'sample-wise L2 normalizing', 0.3399941658305215, '0.06806135177612305')\n",
      "('SGDClassifier', 'Unscaled data', 0.4116196920073438, '2.390923023223877')\n",
      "('SGDClassifier', 'standard scaling', 0.5004161854246673, '0.13472270965576172')\n",
      "('SGDClassifier', 'min-max scaling', 0.4236018917670033, '0.13087749481201172')\n",
      "('SGDClassifier', 'max-abs scaling', 0.47511941931607354, '0.19488811492919922')\n",
      "('SGDClassifier', 'robust scaling', 0.4757893926672812, '0.14870905876159668')\n",
      "('SGDClassifier', 'power transformation (Yeo-Johnson)', 0.5062312738190163, '0.14243388175964355')\n",
      "('SGDClassifier', 'quantile transformation (gaussian pdf)', 0.4719348377457367, '0.1711900234222412')\n",
      "('SGDClassifier', 'quantile transformation (uniform pdf)', 0.4735429629280557, '0.14524626731872559')\n",
      "('SGDClassifier', 'sample-wise L2 normalizing', 0.34784194933686113, '0.23237180709838867')\n",
      "('LinearSVC', 'Unscaled data', 0.28266009269304343, '4.327951908111572')\n",
      "('LinearSVC', 'standard scaling', 0.5247690110095705, '0.0847771167755127')\n",
      "('LinearSVC', 'min-max scaling', 0.5086692068499131, '0.01130056381225586')\n",
      "('LinearSVC', 'max-abs scaling', 0.5086692068499131, '0.012225151062011719')\n",
      "('LinearSVC', 'robust scaling', 0.5236492170588362, '0.029788494110107422')\n",
      "('LinearSVC', 'power transformation (Yeo-Johnson)', 0.5190062934816754, '0.0812227725982666')\n",
      "('LinearSVC', 'quantile transformation (gaussian pdf)', 0.4892246400685045, '0.25319766998291016')\n",
      "('LinearSVC', 'quantile transformation (uniform pdf)', 0.5169560201179064, '0.020738840103149414')\n",
      "('LinearSVC', 'sample-wise L2 normalizing', 0.3551417114841624, '0.018310546875')\n",
      "('SVC', 'Unscaled data', 0.50222476790416, '0.042014122009277344')\n",
      "('SVC', 'standard scaling', 0.5997274644338144, '0.02137470245361328')\n",
      "('SVC', 'min-max scaling', 0.6007303166834735, '0.02177715301513672')\n",
      "('SVC', 'max-abs scaling', 0.6007303166834735, '0.019888877868652344')\n",
      "('SVC', 'robust scaling', 0.5995428249195649, '0.021959543228149414')\n",
      "('SVC', 'power transformation (Yeo-Johnson)', 0.5993896392169089, '0.021653175354003906')\n",
      "('SVC', 'quantile transformation (gaussian pdf)', 0.7658520312976607, '0.022984027862548828')\n",
      "('SVC', 'quantile transformation (uniform pdf)', 0.5957432438085138, '0.02234196662902832')\n",
      "('SVC', 'sample-wise L2 normalizing', 0.3399709109410855, '0.07351303100585938')\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "\n",
    "SLOWHEAD = 10000\n",
    "label=\"nPH\"\n",
    "y_train_fast = traindata[[label]].values.ravel()\n",
    "y_train_slow = traindata.head(SLOWHEAD)[[label]].values.ravel()\n",
    "y_test = testdata[[label]].values.ravel()\n",
    "\n",
    "\n",
    "def train_model(mname, modelorg, speed, sname, x_train, x_test):\n",
    "    # These get killed without error?\n",
    "    if mname == \"RadiusNeighborsClassifier\" and sname != \"Unscaled data\":\n",
    "        return (mname, sname, np.NaN, 'Skipped')\n",
    "    try:\n",
    "        model = sklearn.base.clone(modelorg)\n",
    "        start = time.time()\n",
    "        signal.alarm(int(5 * 60))  # Timeout\n",
    "        if speed == \"slow\":\n",
    "            model.fit(x_train[0:SLOWHEAD], y_train_slow)\n",
    "        elif speed == \"fast\":\n",
    "            model.fit(x_train, y_train_fast)\n",
    "        signal.alarm(0)\n",
    "        end = time.time()\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_true = y_test\n",
    "\n",
    "        bac = balanced_accuracy_score(y_true, y_pred)\n",
    "        return (mname, sname, bac, str(end - start))\n",
    "    except Exception as err:\n",
    "        return (mname, sname, np.NaN, err)\n",
    "\n",
    "\n",
    "results = []\n",
    "for mname, modelorg, speed in models:\n",
    "    out = Parallel(n_jobs=10)(\n",
    "        delayed(train_model)(mname, modelorg, speed, sname, x_train, x_test)\n",
    "        for sname, x_train, x_test in trainscaled\n",
    "    )\n",
    "    for o in out:\n",
    "        results.append(o)\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
